{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70423feb-850c-4286-9b55-7cdca163d412",
   "metadata": {},
   "source": [
    "# LangChain全面剖析之Model I/O"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "deploying\n",
    "WSL2\n",
    "distributions\n",
    "ensuring\n",
    "main\n",
    "distro is deployed: deploying\n",
    "\"docker-desktop\": importing\n",
    "WSL\n",
    "distro\n",
    "\"当前计算机配置不支持 WSL2。\\r\\n请启用“虚拟机平台”可选组件，并确保在 BIOS 中启用虚拟化。\\r\\n通过运行以下命令启用“虚拟机平台”: wsl.exe --install --no-distribution\\r\\n有关信息，请访问 https://aka.ms/enablevirtualization\\r\\n错误代码: Wsl/Service/RegisterDistro/CreateVm/HCS/HCS_E_HYPERV_NOT_INSTALLED\\r\\n\"\n",
    "output = \"docker-desktop\": exit\n",
    "code: 4294967295: running\n",
    "WSL\n",
    "command\n",
    "wsl.exe\n",
    "C:\\Windows\\System32\\wsl.exe - -\n",
    "import docker\n",
    "\n",
    "-desktop < HOME >\\AppData\\Local\\Docker\\wsl\\main\n",
    "C:\\Program\n",
    "Files\\Docker\\Docker\\resources\\wsl\\wsl - bootstrap.tar - -version\n",
    "2: 当前计算机配置不支持\n",
    "WSL2。\n",
    "请启用“虚拟机平台”可选组件，并确保在\n",
    "BIOS\n",
    "中启用虚拟化。\n",
    "通过运行以下命令启用“虚拟机平台”: wsl.exe - -install - -no - distribution\n",
    "有关信息，请访问\n",
    "https: // aka.ms / enablevirtualization\n",
    "错误代码: Wsl / Service / RegisterDistro / CreateVm / HCS / HCS_E_HYPERV_NOT_INSTALLED\n",
    ": exit\n",
    "status\n",
    "0xffffffff\n",
    "checking if isocache\n",
    "exists: CreateFile \\\\wsl$\\docker - desktop - data\\isocache\\: The\n",
    "network\n",
    "name\n",
    "cannot\n",
    "be\n",
    "found."
   ],
   "id": "d465b18f31e3ab91"
  },
  {
   "cell_type": "markdown",
   "id": "a1cc8eeb-529a-4247-946a-8dd8b674893f",
   "metadata": {},
   "source": [
    "## 1. Model I/O介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fdcda3-8a67-4872-9998-099cf09f3ee5",
   "metadata": {},
   "source": [
    "### 1.1 Model I/O模块组成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef3cc1f-2975-4333-bb0e-ee883a1db597",
   "metadata": {},
   "source": [
    "- **Format：即指代Prompts Template，通过模板化来管理大模型的输入；**\n",
    "- **Predict：即指代Models，使用通用接口调用不同的大语言模型；**\n",
    "- **Parse：即指代Output部分，用来从模型的推理中提取信息，并按照预先设定好的模版来规范化输出。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68226771-49d8-472a-9aee-161a8d9d98d2",
   "metadata": {},
   "source": [
    "- **Format**\n",
    "\n",
    "传统上我们创建提示词是通过手工编写来实现的，在这个过程中会利用各种提示工程技巧，如Few-Shot、链式推理（CoT）等方法，以提高大模型的推理性能。然而，在应用\n",
    "开发中，一个关键的考量是提示词不能是一成不变的。其原因在于，应用开发需要适应多变的用户需求和场景。固定的提示词限制了模型的灵活性和适用范围\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a1455e-3468-4ed9-a7d8-2af7d4a5f294",
   "metadata": {},
   "source": [
    "- **Predict**\n",
    "\n",
    "在Predict部分，实质上是处理模型从接收输入到执行推理的整个过程。考虑到存在两种主要类型的大模型——Base类模型和Chat类模型，LangChain在其Model I/O模块中\n",
    "对这两种模型都进行了抽象，分别归类为LLMs（Large Language Models）和Chat Models。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413e651-208f-4ccb-8f93-70a6f7f0afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base类模型\n",
    "# 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\n",
    "client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=\"Say this is a test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25835494-d6d8-4f9c-ae29-203e368dbaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat模型\n",
    "client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一位乐于助人的AI智能小助手\"},\n",
    "        {\"role\": \"user\", \"content\": \"你好，请你介绍一下你自己。\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a3023-9576-49b5-a12d-5cbf761f67e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "- **Parse**\n",
    "\n",
    "大模型的输出是不稳定的，同样的输入Prompt往往会得到不同形式的输出。在自然语言交互中，不同的语言表达方式通常不会造成理解上的障碍。但在应用开发中，大模型的\n",
    "输出可能是下一步逻辑处理的关键输入。因此，在这种情况下，规范化输出是必须要做的任务，以确保应用能够顺利进行后续的逻辑处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd3b841-0cb0-4e11-b7c9-010b565824b3",
   "metadata": {},
   "source": [
    "### 1.2 什么是LCEL？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07878ad-f704-4149-8f31-feaa4d3995f1",
   "metadata": {},
   "source": [
    "LangChain表达式语言（LCEL）是一种声明式方法，可以轻松地将 链 组合在一起。你可以理解为就是类似shell里面管道符的开发方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567fd19c-6b8b-437b-945f-8637c50a2dae",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.3 LangChain安装"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48c05d02-effb-4392-9a15-f71c38e4c31a",
   "metadata": {},
   "source": [
    "! pip install langchain\n",
    "! pip install opeanai"
   ]
  },
  {
   "cell_type": "code",
   "id": "6faad176-5602-42e3-a6de-d4bf14a93106",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-11T12:38:39.455237Z",
     "start_time": "2025-01-11T12:38:39.439994Z"
    }
   },
   "source": [
    "import langchain\n",
    "\n",
    "print(langchain.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.13\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "8a16a850-b726-4d3b-a504-bf938133bd50",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-11T12:38:43.026458Z",
     "start_time": "2025-01-11T12:38:42.253858Z"
    }
   },
   "source": [
    "import openai\n",
    "\n",
    "print(openai.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.58.1\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "54ff95f8-7f2f-4dcb-8aa1-efc56c404141",
   "metadata": {},
   "source": [
    "## 2. Model I/O之模型调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0f6ce7-b9f6-40ec-93b7-dbf3dac7fd86",
   "metadata": {},
   "source": [
    "LangChain为了使开发者可以轻松地创建自定义链，整体采用`Runnable`协议。Runnable 协议是编程中一种常见的设计模式，用于定义可以执行的任务或行为。\n",
    "在LangChain中通过构建标准接口，可以用户轻松定义自定义链并以标准方式调用它们，目前在LangChain已经集成的LLMs中，均实现了`Runnable`接口，目前支持\n",
    "包括`invoke`、 `stream` 、 `batch` 、 `astream` 等方法的调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0e691-757d-4f9a-a3ad-8a26f08a5b7d",
   "metadata": {},
   "source": [
    "LangChain已经集成的大模型：https://python.langchain.com/docs/integrations/llms/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564a60c2-6a00-471a-8d6e-13f648041f02",
   "metadata": {},
   "source": [
    "具体支持的调用方式如下所示：\n",
    "\n",
    "| 方法    | 说明             |\n",
    "|-------|----------------|\n",
    "| invoke | 处理单条输入       |\n",
    "| batch  | 处理批量输入 |\n",
    "| stream | 流式响应         |\n",
    "| ainvoke | 异步处理单条输入       |\n",
    "| abatch  | 异步处理批量输入 |\n",
    "| astream | 异步流式响应         |"
   ]
  },
  {
   "cell_type": "code",
   "id": "108de6a3-121a-41a9-8ca8-acf8dce98993",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T05:50:02.427611Z",
     "start_time": "2025-01-19T05:50:02.273527Z"
    }
   },
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "print(api_key)\n",
    "# api_key = \"sk-5693c407c9774742b633d28163d8fcc7\"\n",
    "# api_base=\"https://newone.nxykj.tech/v1\"\n",
    "api_base = \"https://api.deepseek.com\"\n",
    "client = OpenAI(api_key=api_key, base_url=api_base)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-5693c407c9774742b633d28163d8fcc7\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "23ac8176-773e-4074-8d13-4c3684e26517",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T05:58:55.433531Z",
     "start_time": "2025-01-18T05:58:52.425929Z"
    }
   },
   "source": [
    "completion = client.chat.completions.create(\n",
    "    # model=\"gpt-3.5-turbo\",\n",
    "    # model=\"deepseek-chat\",\n",
    "    model=\"deepseek-coder\",\n",
    "    # model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个乐于助人的智能AI小助手\"},\n",
    "        {\"role\": \"user\", \"content\": \"你好，请你介绍一下你自己\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是一个由OpenAI开发的人工智能助手，旨在通过自然语言处理和机器学习技术来帮助用户解答问题、提供信息、执行任务和进行对话。我可以协助你完成各种任务，比如查找信息、学习新知识、翻译语言、编写代码、提供建议等。\n",
      "\n",
      "我的知识库涵盖了广泛的主题，包括科学、技术、历史、文化、日常生活等。不过，我的知识截止到2021年，因此对于2021年之后的事件或信息，我可能无法提供最新的内容。\n",
      "\n",
      "如果你有任何问题或需要帮助，随时告诉我！😊\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "38802685-7970-42ad-9bff-b677289d5914",
   "metadata": {},
   "source": [
    "LangChain作为一个应用开发框架，需要集成各种不同的大模型，如上述OpenAI的GPT系列模型调用示例，通过Message数据输入规范，定义不同的role，即system、user和assistant来区分对话过程，但对于其他大模型，并不意味这一定会遵守这种输入输出及角色的定义，所以LangChain的做法是，因为Chat Model基于消息而不是原始文本，LangChain目前就抽象出来的消息类型有 AIMessage 、 HumanMessage 、 SystemMessage 、 FunctionMessage 和 ChatMessage ，但大多时候我们只需要处理 HumanMessage 、 AIMessage 和 SystemMessage，即：\n",
    "- SystemMessage ：用于启动 AI 行为，作为输入消息序列中的第一个传入。\n",
    "- HumanMessage ：表示来自与聊天模型交互的人的消息。\n",
    "- AIMessage ：表示来自聊天模型的消息。这可以是文本，也可以是调用工具的请求。"
   ]
  },
  {
   "cell_type": "code",
   "id": "cef55559-0cb8-4c5f-b4d7-286bb1e2ee3d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T01:46:40.936113Z",
     "start_time": "2025-01-09T01:46:38.061701Z"
    }
   },
   "source": [
    "!pip install langchain-openai"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-openai) (0.3.28)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-openai) (1.58.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (0.2.6)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (2.10.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-openai) (3.10.13)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.27->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.27->langchain-openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n",
      "Requirement already satisfied: colorama in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.58.1->langchain-openai) (0.4.6)\n",
      "Downloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
      "Installing collected packages: langchain-openai\n",
      "Successfully installed langchain-openai-0.2.14\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "b83dcfa8-e57e-448f-afe4-d264058f508d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T01:51:28.686319Z",
     "start_time": "2025-01-09T01:51:28.457265Z"
    }
   },
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "58d31be6-97c9-43fd-a31a-ba4c43a505f1",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T01:51:29.410739Z",
     "start_time": "2025-01-09T01:51:29.408155Z"
    }
   },
   "source": [
    "messages = [SystemMessage(content=\"你是一位乐于助人的智能小助手\"),\n",
    "            HumanMessage(content=\"你好，请你介绍一下你自己\"), ]"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "c5cf93bd-11e5-4353-b294-6052553f5edd",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T01:51:30.252974Z",
     "start_time": "2025-01-09T01:51:30.247466Z"
    }
   },
   "source": [
    "messages"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一位乐于助人的智能小助手', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='你好，请你介绍一下你自己', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "3c3e47fb-df7d-4db3-b0a8-34d0072c5fe2",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T05:50:25.510642Z",
     "start_time": "2025-01-19T05:50:25.231381Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"deepseek-chat\", api_key=api_key, base_url=api_base)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "3c4f6e58-3e13-44d3-9b95-88b3ea66fefe",
   "metadata": {},
   "source": [
    "#### invoke"
   ]
  },
  {
   "cell_type": "code",
   "id": "7cf91194-4d3e-4c57-ae3e-6faf70c5c8b0",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T01:51:55.616561Z",
     "start_time": "2025-01-09T01:51:52.513462Z"
    }
   },
   "source": [
    "chat.invoke(messages)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！我是一个由OpenAI开发的人工智能助手，旨在通过自然语言处理和机器学习技术来帮助用户解答问题、提供信息、执行任务和进行对话。我可以协助你完成各种任务，比如查找资料、学习新知识、解决数学问题、提供建议、翻译语言等。\\n\\n我的知识库涵盖了广泛的主题，包括科学、技术、历史、文化、日常生活等。我可以根据你的需求提供详细的信息或简明的回答。如果你有任何问题或需要帮助，随时可以问我！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 101, 'prompt_tokens': 16, 'total_tokens': 117, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 16}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3a5770e1b4', 'finish_reason': 'stop', 'logprobs': None}, id='run-bb81159b-4956-41ab-a985-e2a6596a856f-0', usage_metadata={'input_tokens': 16, 'output_tokens': 101, 'total_tokens': 117, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec76feb8-7547-49a0-8eb7-6acd97651b57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好！我是一个智能助手，可以回答各种问题，提供信息和帮助解决问题。我可以谈论各种话题，包括历史、科学、技术、健康、娱乐等等。有什么我可以帮到你的吗？'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(messages).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2818d8-8b0b-4480-8cee-c8ae53a8e69f",
   "metadata": {},
   "source": "#### stream"
  },
  {
   "cell_type": "code",
   "id": "8bee6bd0-a3aa-48e8-a7d8-3246a286571d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T02:14:47.744906Z",
     "start_time": "2025-01-09T02:14:45.225663Z"
    }
   },
   "source": [
    "for chunk in chat.stream(messages):\n",
    "    print(chunk.content, \"\\n---\\n\", end=\"\", flush=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "---\n",
      "你好 \n",
      "---\n",
      "！ \n",
      "---\n",
      "我是一个 \n",
      "---\n",
      "由 \n",
      "---\n",
      "Open \n",
      "---\n",
      "AI \n",
      "---\n",
      "开发 \n",
      "---\n",
      "的人工 \n",
      "---\n",
      "智能 \n",
      "---\n",
      "助手 \n",
      "---\n",
      "， \n",
      "---\n",
      "旨在 \n",
      "---\n",
      "帮助 \n",
      "---\n",
      "用户 \n",
      "---\n",
      "解答 \n",
      "---\n",
      "问题 \n",
      "---\n",
      "、 \n",
      "---\n",
      "提供 \n",
      "---\n",
      "信息 \n",
      "---\n",
      "、 \n",
      "---\n",
      "执行 \n",
      "---\n",
      "任务 \n",
      "---\n",
      "和 \n",
      "---\n",
      "进行 \n",
      "---\n",
      "对话 \n",
      "---\n",
      "。 \n",
      "---\n",
      "我可以 \n",
      "---\n",
      "协助 \n",
      "---\n",
      "你 \n",
      "---\n",
      "完成 \n",
      "---\n",
      "各种 \n",
      "---\n",
      "任务 \n",
      "---\n",
      "， \n",
      "---\n",
      "比如 \n",
      "---\n",
      "查找 \n",
      "---\n",
      "资料 \n",
      "---\n",
      "、 \n",
      "---\n",
      "学习 \n",
      "---\n",
      "新 \n",
      "---\n",
      "知识 \n",
      "---\n",
      "、 \n",
      "---\n",
      "解决 \n",
      "---\n",
      "技术 \n",
      "---\n",
      "问题 \n",
      "---\n",
      "、 \n",
      "---\n",
      "提供 \n",
      "---\n",
      "建议 \n",
      "---\n",
      "等 \n",
      "---\n",
      "。 \n",
      "---\n",
      "我的 \n",
      "---\n",
      "知识 \n",
      "---\n",
      "库 \n",
      "---\n",
      "涵盖了 \n",
      "---\n",
      "广泛 \n",
      "---\n",
      "的主题 \n",
      "---\n",
      "， \n",
      "---\n",
      "并且 \n",
      "---\n",
      "我会 \n",
      "---\n",
      "尽力 \n",
      "---\n",
      "提供 \n",
      "---\n",
      "准确 \n",
      "---\n",
      "和 \n",
      "---\n",
      "有用的 \n",
      "---\n",
      "信息 \n",
      "---\n",
      "。 \n",
      "---\n",
      "如果你 \n",
      "---\n",
      "有任何 \n",
      "---\n",
      "问题 \n",
      "---\n",
      "或 \n",
      "---\n",
      "需要 \n",
      "---\n",
      "帮助 \n",
      "---\n",
      "， \n",
      "---\n",
      "随时 \n",
      "---\n",
      "告诉我 \n",
      "---\n",
      "！ \n",
      "---\n",
      " \n",
      "---\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "6f913448-cc24-45bf-b0e7-b7f79563a6df",
   "metadata": {},
   "source": [
    "#### batch"
   ]
  },
  {
   "cell_type": "code",
   "id": "ef80ec30-3885-4262-8aa2-655f09eae63c",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T02:16:17.841255Z",
     "start_time": "2025-01-09T02:16:01.037782Z"
    }
   },
   "source": [
    "messages1 = [SystemMessage(content=\"你是一位乐于助人的智能小助手\"),\n",
    "             HumanMessage(content=\"请帮我介绍一下什么是机器学习\"), ]\n",
    "for chunk in chat.stream(messages1):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "机器学习（Machine Learning, ML）是人工智能（AI）的一个子领域，旨在通过数据和算法让计算机系统具备“学习”能力，从而在没有明确编程指令的情况下完成任务或改进性能。机器学习的核心思想是通过从数据中提取模式或规律，使计算机能够自动进行预测、分类、决策等任务。\n",
      "\n",
      "### 机器学习的基本概念\n",
      "1. **数据**：机器学习的基础是数据。数据可以是结构化的（如表格数据）或非结构化的（如文本、图像、音频等）。数据质量直接影响模型的效果。\n",
      "2. **模型**：模型是机器学习的核心，它是一个数学函数或算法，用于从数据中学习规律。模型可以是简单的线性回归，也可以是复杂的深度神经网络。\n",
      "3. **训练**：训练是指通过输入数据让模型学习的过程。模型会根据数据调整其内部参数，以最小化预测误差。\n",
      "4. **测试与验证**：在训练完成后，需要使用未见过的数据（测试集）来评估模型的性能，以确保其泛化能力（即对新数据的适应能力）。\n",
      "5. **特征**：特征是数据的属性或变量，用于描述数据的某些方面。特征选择对模型性能至关重要。\n",
      "\n",
      "### 机器学习的类型\n",
      "1. **监督学习（Supervised Learning）**：\n",
      "   - 输入数据包含输入特征和对应的标签（目标值）。\n",
      "   - 目标是学习一个从输入到输出的映射函数。\n",
      "   - 常见任务：分类（如图像分类）、回归（如房价预测）。\n",
      "   - 常用算法：线性回归、逻辑回归、支持向量机（SVM）、决策树、随机森林、神经网络等。\n",
      "\n",
      "2. **无监督学习（Unsupervised Learning）**：\n",
      "   - 输入数据没有标签，模型需要自行发现数据中的结构或模式。\n",
      "   - 常见任务：聚类（如客户分群）、降维（如PCA）、异常检测。\n",
      "   - 常用算法：K均值聚类、层次聚类、主成分分析（PCA）、自编码器等。\n",
      "\n",
      "3. **强化学习（Reinforcement Learning）**：\n",
      "   - 模型通过与环境的交互来学习策略，以最大化某种奖励信号。\n",
      "   - 常见任务：游戏AI（如AlphaGo）、机器人控制、自动驾驶。\n",
      "   - 常用算法：Q学习、深度Q网络（DQN）、策略梯度方法等。\n",
      "\n",
      "4. **半监督学习（Semi-supervised Learning）**：\n",
      "   - 结合少量标注数据和大量未标注数据进行训练。\n",
      "   - 适用于标注成本高的场景。\n",
      "\n",
      "5. **自监督学习（Self-supervised Learning）**：\n",
      "   - 通过设计任务从数据中自动生成标签，用于训练模型。\n",
      "   - 常见于自然语言处理和计算机视觉领域。\n",
      "\n",
      "### 机器学习的应用\n",
      "机器学习已广泛应用于各个领域，包括但不限于：\n",
      "- **计算机视觉**：图像分类、目标检测、人脸识别。\n",
      "- **自然语言处理**：机器翻译、情感分析、聊天机器人。\n",
      "- **推荐系统**：电商推荐、视频推荐。\n",
      "- **医疗**：疾病诊断、药物研发。\n",
      "- **金融**：风险评估、股票预测。\n",
      "- **自动驾驶**：路径规划、环境感知。\n",
      "\n",
      "### 机器学习的挑战\n",
      "1. **数据质量**：噪声数据、缺失数据、不平衡数据会影响模型性能。\n",
      "2. **过拟合**：模型在训练数据上表现很好，但在新数据上表现差。\n",
      "3. **计算资源**：深度学习模型通常需要大量计算资源和时间。\n",
      "4. **可解释性**：复杂模型（如深度学习）的决策过程难以解释。\n",
      "5. **伦理问题**：数据隐私、算法偏见等。\n",
      "\n",
      "### 总结\n",
      "机器学习是一种强大的工具，能够从数据中提取知识并应用于实际问题。随着数据量的增加和计算能力的提升，机器学习在科学研究、工业应用和日常生活中扮演着越来越重要的角色。如果你对机器学习感兴趣，可以从学习基础算法和编程工具（如Python、TensorFlow、PyTorch）开始，逐步深入探索这一领域。"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "1154c3b3-8405-4b67-a0f6-6432e9e7484f",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T02:09:36.876531Z",
     "start_time": "2025-01-09T02:09:36.873694Z"
    }
   },
   "source": [
    "messages2 = [SystemMessage(content=\"你是一位乐于助人的智能小助手\"),\n",
    "             HumanMessage(content=\"请帮我介绍一下什么是AIGC\"), ]"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "30c6cb82-b79b-4059-a5d0-a78974f2a765",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T02:09:38.648173Z",
     "start_time": "2025-01-09T02:09:38.644790Z"
    }
   },
   "source": [
    "messages3 = [SystemMessage(content=\"你是一位乐于助人的智能小助手\"),\n",
    "             HumanMessage(content=\"请帮我介绍一下什么是大模型技术\"), ]"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "991062c2-721d-4fa4-8d51-7f01357c277a",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T02:09:57.553948Z",
     "start_time": "2025-01-09T02:09:41.603996Z"
    }
   },
   "source": [
    "reponse = chat.batch([messages1,\n",
    "                      messages2,\n",
    "                      messages3, ])\n",
    "\n",
    "reponse"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='机器学习（Machine Learning, ML）是人工智能（AI）的一个子领域，专注于通过数据和经验让计算机系统自动改进其性能。简单来说，机器学习是一种让计算机从数据中学习规律并做出预测或决策的技术，而无需显式编程。\\n\\n### 机器学习的核心思想\\n机器学习的核心思想是通过数据训练模型，使模型能够从输入数据中提取特征并做出推断。其过程通常包括以下几个步骤：\\n1. **数据收集**：获取用于训练和测试的数据。\\n2. **数据预处理**：清洗、整理和转换数据，使其适合模型使用。\\n3. **模型选择**：根据任务选择合适的算法或模型。\\n4. **训练模型**：使用训练数据调整模型参数，使其能够拟合数据。\\n5. **评估模型**：使用测试数据评估模型的性能。\\n6. **优化与部署**：优化模型并应用于实际问题。\\n\\n### 机器学习的类型\\n机器学习主要分为三大类：\\n1. **监督学习（Supervised Learning）**：\\n   - 通过带有标签的数据（输入和输出对）训练模型。\\n   - 目标是学习输入到输出的映射关系。\\n   - 常见任务：分类（如图像分类）、回归（如房价预测）。\\n   - 常用算法：线性回归、逻辑回归、支持向量机（SVM）、决策树、神经网络等。\\n\\n2. **无监督学习（Unsupervised Learning）**：\\n   - 使用未标注的数据训练模型。\\n   - 目标是发现数据中的隐藏结构或模式。\\n   - 常见任务：聚类（如客户细分）、降维（如PCA）、异常检测。\\n   - 常用算法：K均值聚类、层次聚类、主成分分析（PCA）、自编码器等。\\n\\n3. **强化学习（Reinforcement Learning）**：\\n   - 通过与环境交互学习策略，以最大化某种奖励信号。\\n   - 目标是学习一系列动作以达到长期目标。\\n   - 常见应用：游戏AI（如AlphaGo）、机器人控制、自动驾驶。\\n   - 常用算法：Q学习、深度Q网络（DQN）、策略梯度方法等。\\n\\n### 机器学习的应用\\n机器学习已广泛应用于各个领域，包括但不限于：\\n- **计算机视觉**：图像分类、目标检测、人脸识别。\\n- **自然语言处理**：机器翻译、情感分析、聊天机器人。\\n- **推荐系统**：电商推荐、视频推荐（如Netflix、YouTube）。\\n- **医疗健康**：疾病诊断、药物研发、医学影像分析。\\n- **金融领域**：风险评估、股票预测、欺诈检测。\\n\\n### 机器学习的挑战\\n尽管机器学习取得了巨大进展，但仍面临一些挑战：\\n1. **数据质量**：数据噪声、缺失值或不平衡数据会影响模型性能。\\n2. **过拟合**：模型在训练数据上表现很好，但在新数据上表现不佳。\\n3. **可解释性**：某些复杂模型（如深度学习）的决策过程难以解释。\\n4. **计算资源**：训练大规模模型需要大量计算资源和时间。\\n5. **伦理问题**：数据隐私、算法偏见等问题需要关注。\\n\\n### 总结\\n机器学习是一种强大的工具，能够从数据中提取知识并解决复杂问题。随着数据量的增长和计算能力的提升，机器学习正在推动人工智能的快速发展，并在各行各业中发挥越来越重要的作用。如果你对机器学习感兴趣，可以从学习基础算法和编程工具（如Python、TensorFlow、PyTorch）开始，逐步深入探索这一领域。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 715, 'prompt_tokens': 16, 'total_tokens': 731, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 16}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3a5770e1b4', 'finish_reason': 'stop', 'logprobs': None}, id='run-e45037e2-1ee8-488b-af6f-9abad4b8003d-0', usage_metadata={'input_tokens': 16, 'output_tokens': 715, 'total_tokens': 731, 'input_token_details': {}, 'output_token_details': {}}),\n",
       " AIMessage(content='AIGC（Artificial Intelligence Generated Content）即人工智能生成内容，是指利用人工智能技术自动生成文本、图像、音频、视频等多种形式的内容。AIGC的核心在于通过机器学习、深度学习等AI技术，使计算机能够模仿人类的创作过程，生成具有逻辑性、连贯性和创造性的内容。\\n\\n### AIGC的主要应用领域\\n1. **文本生成**：如新闻写作、小说创作、广告文案、技术文档等。典型代表是OpenAI的GPT系列模型，能够生成高质量的文本内容。\\n2. **图像生成**：如艺术创作、设计素材、广告图片等。典型代表是DALL·E、MidJourney等工具，可以根据文字描述生成图像。\\n3. **音频生成**：如音乐创作、语音合成、配音等。典型代表是Google的WaveNet、OpenAI的Jukedeck等。\\n4. **视频生成**：如短视频制作、动画生成、虚拟主播等。典型代表是Synthesia、Runway ML等工具。\\n5. **代码生成**：如自动编写代码、调试程序等。典型代表是GitHub Copilot，能够根据需求生成代码片段。\\n\\n### AIGC的技术基础\\n1. **自然语言处理（NLP）**：用于文本生成和理解，如GPT、BERT等模型。\\n2. **计算机视觉（CV）**：用于图像和视频生成，如GAN（生成对抗网络）、扩散模型等。\\n3. **语音合成与识别**：用于音频生成和处理，如TTS（文本转语音）技术。\\n4. **强化学习与生成模型**：用于优化生成内容的质量和多样性。\\n\\n### AIGC的优势\\n1. **高效性**：能够快速生成大量内容，节省时间和人力成本。\\n2. **多样性**：可以根据需求生成不同风格、形式的内容。\\n3. **创新性**：AI能够结合大量数据，生成人类难以想到的创意内容。\\n4. **可定制化**：用户可以通过输入特定需求，生成符合个性化需求的内容。\\n\\n### AIGC的挑战\\n1. **内容质量**：生成的内容可能存在逻辑错误、重复或不连贯的问题。\\n2. **伦理与版权**：AI生成的内容可能涉及版权争议或伦理问题，如虚假信息、隐私泄露等。\\n3. **技术门槛**：高质量的AIGC需要强大的算力和数据支持，对普通用户来说可能难以实现。\\n4. **人类创作的独特性**：AI生成的内容可能缺乏人类情感和深度，难以完全替代人类创作。\\n\\n### 未来展望\\nAIGC正在快速发展，未来可能在教育、娱乐、广告、医疗等领域发挥更大作用。随着技术的进步，AIGC将更加智能化、个性化和普及化，成为人类创作的重要辅助工具。同时，如何平衡AI生成内容与人类创作的独特性，以及如何解决伦理和法律问题，将是未来需要重点关注的方向。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 599, 'prompt_tokens': 18, 'total_tokens': 617, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 18}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3a5770e1b4', 'finish_reason': 'stop', 'logprobs': None}, id='run-baeed65e-319a-4f0c-8848-e47157aab7a7-0', usage_metadata={'input_tokens': 18, 'output_tokens': 599, 'total_tokens': 617, 'input_token_details': {}, 'output_token_details': {}}),\n",
       " AIMessage(content='大模型技术（Large Model Technology）是指利用大规模数据集和强大的计算资源，训练出具有极高参数量和复杂结构的机器学习模型。这些模型通常属于深度学习领域，能够处理复杂的任务，如自然语言处理（NLP）、计算机视觉、语音识别等。大模型技术的核心在于其“大”，主要体现在以下几个方面：\\n\\n### 1. **参数量大**\\n   - 大模型的参数量通常在**数十亿到数万亿**之间。例如，OpenAI的GPT-3模型有1750亿个参数，而Google的PaLM模型有5400亿个参数。\\n   - 参数量的增加使得模型能够捕捉到更复杂的模式和更细微的特征，从而提升模型的性能。\\n\\n### 2. **数据规模大**\\n   - 大模型的训练需要**海量的数据**。这些数据通常来自互联网、书籍、论文、社交媒体等多种来源。\\n   - 大规模数据集的多样性使得模型能够学习到更广泛的知识，从而具备更强的泛化能力。\\n\\n### 3. **计算资源需求大**\\n   - 训练大模型需要**强大的计算资源**，通常依赖于高性能的GPU或TPU集群。\\n   - 训练过程可能需要数周甚至数月的时间，消耗大量的电力和计算资源。\\n\\n### 4. **应用范围广**\\n   - 大模型技术在多个领域都有广泛的应用，包括但不限于：\\n     - **自然语言处理**：如文本生成、机器翻译、问答系统、情感分析等。\\n     - **计算机视觉**：如图像分类、目标检测、图像生成等。\\n     - **语音识别与合成**：如语音转文字、语音助手等。\\n     - **多模态任务**：如结合文本和图像的任务（图像描述生成、视觉问答等）。\\n\\n### 5. **代表性模型**\\n   - **GPT系列**（OpenAI）：如GPT-3、GPT-4，主要用于自然语言处理任务。\\n   - **BERT**（Google）：一种基于Transformer的预训练模型，广泛应用于文本分类、问答等任务。\\n   - **T5**（Google）：一种多任务学习的文本生成模型。\\n   - **PaLM**（Google）：一种大规模语言模型，参数量达到5400亿。\\n   - **DALL-E**（OpenAI）：一种结合文本和图像的生成模型，能够根据文本描述生成图像。\\n\\n### 6. **优势**\\n   - **强大的泛化能力**：大模型能够在未见过的数据上表现出色，适用于多种任务。\\n   - **多任务学习**：一个模型可以同时处理多个任务，减少了针对每个任务单独训练模型的需求。\\n   - **零样本或少样本学习**：大模型能够在没有或只有少量标注数据的情况下完成任务。\\n\\n### 7. **挑战**\\n   - **计算成本高**：训练和部署大模型需要大量的计算资源，成本高昂。\\n   - **能源消耗大**：训练大模型会消耗大量电力，对环境产生影响。\\n   - **模型解释性差**：大模型的复杂性使得其决策过程难以解释，存在“黑箱”问题。\\n   - **数据偏见**：大模型可能会继承训练数据中的偏见，导致不公平或有害的输出。\\n\\n### 8. **未来发展方向**\\n   - **模型压缩与优化**：通过模型剪枝、量化等技术减少模型的计算和存储需求。\\n   - **绿色AI**：开发更高效的训练方法，减少能源消耗。\\n   - **多模态融合**：进一步提升模型在文本、图像、语音等多模态任务上的表现。\\n   - **可解释性研究**：提高模型的可解释性，使其决策过程更加透明。\\n\\n总之，大模型技术是当前人工智能领域的前沿方向之一，具有广泛的应用前景，但也面临着诸多挑战。随着技术的不断进步，大模型有望在更多领域发挥重要作用。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 784, 'prompt_tokens': 18, 'total_tokens': 802, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 18}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3a5770e1b4', 'finish_reason': 'stop', 'logprobs': None}, id='run-843a7919-f413-4afb-84ea-da92f76a7ad2-0', usage_metadata={'input_tokens': 18, 'output_tokens': 784, 'total_tokens': 802, 'input_token_details': {}, 'output_token_details': {}})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "caa53907-7a62-4ac2-805a-7d4f3401c685",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T02:21:04.566372Z",
     "start_time": "2025-01-09T02:21:04.562692Z"
    }
   },
   "source": [
    "# 格式化输出\n",
    "\n",
    "# 使用列表生成式打印每一个消息的内容\n",
    "contents = [msg.content for msg in reponse]\n",
    "\n",
    "# 打印出内容\n",
    "for content in contents:\n",
    "    print(content, \"\\n---\\n\")\n",
    "# for chunk in chat.stream([messages1,\n",
    "#                           messages2,\n",
    "#                           messages3, ]):\n",
    "#     print(chunk.content, \"\\n---\\n\", end=\"\", flush=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "机器学习（Machine Learning, ML）是人工智能（AI）的一个子领域，专注于通过数据和经验让计算机系统自动改进其性能。简单来说，机器学习是一种让计算机从数据中学习规律并做出预测或决策的技术，而无需显式编程。\n",
      "\n",
      "### 机器学习的核心思想\n",
      "机器学习的核心思想是通过数据训练模型，使模型能够从输入数据中提取特征并做出推断。其过程通常包括以下几个步骤：\n",
      "1. **数据收集**：获取用于训练和测试的数据。\n",
      "2. **数据预处理**：清洗、整理和转换数据，使其适合模型使用。\n",
      "3. **模型选择**：根据任务选择合适的算法或模型。\n",
      "4. **训练模型**：使用训练数据调整模型参数，使其能够拟合数据。\n",
      "5. **评估模型**：使用测试数据评估模型的性能。\n",
      "6. **优化与部署**：优化模型并应用于实际问题。\n",
      "\n",
      "### 机器学习的类型\n",
      "机器学习主要分为三大类：\n",
      "1. **监督学习（Supervised Learning）**：\n",
      "   - 通过带有标签的数据（输入和输出对）训练模型。\n",
      "   - 目标是学习输入到输出的映射关系。\n",
      "   - 常见任务：分类（如图像分类）、回归（如房价预测）。\n",
      "   - 常用算法：线性回归、逻辑回归、支持向量机（SVM）、决策树、神经网络等。\n",
      "\n",
      "2. **无监督学习（Unsupervised Learning）**：\n",
      "   - 使用未标注的数据训练模型。\n",
      "   - 目标是发现数据中的隐藏结构或模式。\n",
      "   - 常见任务：聚类（如客户细分）、降维（如PCA）、异常检测。\n",
      "   - 常用算法：K均值聚类、层次聚类、主成分分析（PCA）、自编码器等。\n",
      "\n",
      "3. **强化学习（Reinforcement Learning）**：\n",
      "   - 通过与环境交互学习策略，以最大化某种奖励信号。\n",
      "   - 目标是学习一系列动作以达到长期目标。\n",
      "   - 常见应用：游戏AI（如AlphaGo）、机器人控制、自动驾驶。\n",
      "   - 常用算法：Q学习、深度Q网络（DQN）、策略梯度方法等。\n",
      "\n",
      "### 机器学习的应用\n",
      "机器学习已广泛应用于各个领域，包括但不限于：\n",
      "- **计算机视觉**：图像分类、目标检测、人脸识别。\n",
      "- **自然语言处理**：机器翻译、情感分析、聊天机器人。\n",
      "- **推荐系统**：电商推荐、视频推荐（如Netflix、YouTube）。\n",
      "- **医疗健康**：疾病诊断、药物研发、医学影像分析。\n",
      "- **金融领域**：风险评估、股票预测、欺诈检测。\n",
      "\n",
      "### 机器学习的挑战\n",
      "尽管机器学习取得了巨大进展，但仍面临一些挑战：\n",
      "1. **数据质量**：数据噪声、缺失值或不平衡数据会影响模型性能。\n",
      "2. **过拟合**：模型在训练数据上表现很好，但在新数据上表现不佳。\n",
      "3. **可解释性**：某些复杂模型（如深度学习）的决策过程难以解释。\n",
      "4. **计算资源**：训练大规模模型需要大量计算资源和时间。\n",
      "5. **伦理问题**：数据隐私、算法偏见等问题需要关注。\n",
      "\n",
      "### 总结\n",
      "机器学习是一种强大的工具，能够从数据中提取知识并解决复杂问题。随着数据量的增长和计算能力的提升，机器学习正在推动人工智能的快速发展，并在各行各业中发挥越来越重要的作用。如果你对机器学习感兴趣，可以从学习基础算法和编程工具（如Python、TensorFlow、PyTorch）开始，逐步深入探索这一领域。 \n",
      "---\n",
      "\n",
      "AIGC（Artificial Intelligence Generated Content）即人工智能生成内容，是指利用人工智能技术自动生成文本、图像、音频、视频等多种形式的内容。AIGC的核心在于通过机器学习、深度学习等AI技术，使计算机能够模仿人类的创作过程，生成具有逻辑性、连贯性和创造性的内容。\n",
      "\n",
      "### AIGC的主要应用领域\n",
      "1. **文本生成**：如新闻写作、小说创作、广告文案、技术文档等。典型代表是OpenAI的GPT系列模型，能够生成高质量的文本内容。\n",
      "2. **图像生成**：如艺术创作、设计素材、广告图片等。典型代表是DALL·E、MidJourney等工具，可以根据文字描述生成图像。\n",
      "3. **音频生成**：如音乐创作、语音合成、配音等。典型代表是Google的WaveNet、OpenAI的Jukedeck等。\n",
      "4. **视频生成**：如短视频制作、动画生成、虚拟主播等。典型代表是Synthesia、Runway ML等工具。\n",
      "5. **代码生成**：如自动编写代码、调试程序等。典型代表是GitHub Copilot，能够根据需求生成代码片段。\n",
      "\n",
      "### AIGC的技术基础\n",
      "1. **自然语言处理（NLP）**：用于文本生成和理解，如GPT、BERT等模型。\n",
      "2. **计算机视觉（CV）**：用于图像和视频生成，如GAN（生成对抗网络）、扩散模型等。\n",
      "3. **语音合成与识别**：用于音频生成和处理，如TTS（文本转语音）技术。\n",
      "4. **强化学习与生成模型**：用于优化生成内容的质量和多样性。\n",
      "\n",
      "### AIGC的优势\n",
      "1. **高效性**：能够快速生成大量内容，节省时间和人力成本。\n",
      "2. **多样性**：可以根据需求生成不同风格、形式的内容。\n",
      "3. **创新性**：AI能够结合大量数据，生成人类难以想到的创意内容。\n",
      "4. **可定制化**：用户可以通过输入特定需求，生成符合个性化需求的内容。\n",
      "\n",
      "### AIGC的挑战\n",
      "1. **内容质量**：生成的内容可能存在逻辑错误、重复或不连贯的问题。\n",
      "2. **伦理与版权**：AI生成的内容可能涉及版权争议或伦理问题，如虚假信息、隐私泄露等。\n",
      "3. **技术门槛**：高质量的AIGC需要强大的算力和数据支持，对普通用户来说可能难以实现。\n",
      "4. **人类创作的独特性**：AI生成的内容可能缺乏人类情感和深度，难以完全替代人类创作。\n",
      "\n",
      "### 未来展望\n",
      "AIGC正在快速发展，未来可能在教育、娱乐、广告、医疗等领域发挥更大作用。随着技术的进步，AIGC将更加智能化、个性化和普及化，成为人类创作的重要辅助工具。同时，如何平衡AI生成内容与人类创作的独特性，以及如何解决伦理和法律问题，将是未来需要重点关注的方向。 \n",
      "---\n",
      "\n",
      "大模型技术（Large Model Technology）是指利用大规模数据集和强大的计算资源，训练出具有极高参数量和复杂结构的机器学习模型。这些模型通常属于深度学习领域，能够处理复杂的任务，如自然语言处理（NLP）、计算机视觉、语音识别等。大模型技术的核心在于其“大”，主要体现在以下几个方面：\n",
      "\n",
      "### 1. **参数量大**\n",
      "   - 大模型的参数量通常在**数十亿到数万亿**之间。例如，OpenAI的GPT-3模型有1750亿个参数，而Google的PaLM模型有5400亿个参数。\n",
      "   - 参数量的增加使得模型能够捕捉到更复杂的模式和更细微的特征，从而提升模型的性能。\n",
      "\n",
      "### 2. **数据规模大**\n",
      "   - 大模型的训练需要**海量的数据**。这些数据通常来自互联网、书籍、论文、社交媒体等多种来源。\n",
      "   - 大规模数据集的多样性使得模型能够学习到更广泛的知识，从而具备更强的泛化能力。\n",
      "\n",
      "### 3. **计算资源需求大**\n",
      "   - 训练大模型需要**强大的计算资源**，通常依赖于高性能的GPU或TPU集群。\n",
      "   - 训练过程可能需要数周甚至数月的时间，消耗大量的电力和计算资源。\n",
      "\n",
      "### 4. **应用范围广**\n",
      "   - 大模型技术在多个领域都有广泛的应用，包括但不限于：\n",
      "     - **自然语言处理**：如文本生成、机器翻译、问答系统、情感分析等。\n",
      "     - **计算机视觉**：如图像分类、目标检测、图像生成等。\n",
      "     - **语音识别与合成**：如语音转文字、语音助手等。\n",
      "     - **多模态任务**：如结合文本和图像的任务（图像描述生成、视觉问答等）。\n",
      "\n",
      "### 5. **代表性模型**\n",
      "   - **GPT系列**（OpenAI）：如GPT-3、GPT-4，主要用于自然语言处理任务。\n",
      "   - **BERT**（Google）：一种基于Transformer的预训练模型，广泛应用于文本分类、问答等任务。\n",
      "   - **T5**（Google）：一种多任务学习的文本生成模型。\n",
      "   - **PaLM**（Google）：一种大规模语言模型，参数量达到5400亿。\n",
      "   - **DALL-E**（OpenAI）：一种结合文本和图像的生成模型，能够根据文本描述生成图像。\n",
      "\n",
      "### 6. **优势**\n",
      "   - **强大的泛化能力**：大模型能够在未见过的数据上表现出色，适用于多种任务。\n",
      "   - **多任务学习**：一个模型可以同时处理多个任务，减少了针对每个任务单独训练模型的需求。\n",
      "   - **零样本或少样本学习**：大模型能够在没有或只有少量标注数据的情况下完成任务。\n",
      "\n",
      "### 7. **挑战**\n",
      "   - **计算成本高**：训练和部署大模型需要大量的计算资源，成本高昂。\n",
      "   - **能源消耗大**：训练大模型会消耗大量电力，对环境产生影响。\n",
      "   - **模型解释性差**：大模型的复杂性使得其决策过程难以解释，存在“黑箱”问题。\n",
      "   - **数据偏见**：大模型可能会继承训练数据中的偏见，导致不公平或有害的输出。\n",
      "\n",
      "### 8. **未来发展方向**\n",
      "   - **模型压缩与优化**：通过模型剪枝、量化等技术减少模型的计算和存储需求。\n",
      "   - **绿色AI**：开发更高效的训练方法，减少能源消耗。\n",
      "   - **多模态融合**：进一步提升模型在文本、图像、语音等多模态任务上的表现。\n",
      "   - **可解释性研究**：提高模型的可解释性，使其决策过程更加透明。\n",
      "\n",
      "总之，大模型技术是当前人工智能领域的前沿方向之一，具有广泛的应用前景，但也面临着诸多挑战。随着技术的不断进步，大模型有望在更多领域发挥重要作用。 \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "f6eb2187-187c-4049-a317-c6701dafe9e4",
   "metadata": {},
   "source": [
    "#### 异步"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c771ba4d-e02d-4fee-b148-7704309c8310",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`llm.invoke(...)`本质上是一个同步调用。在这种情况下，程序会在调用返回结果之前停止执行任何后续代码。这意味着如果`invoke`操作耗时较长，它会导致程序暂时挂起，直到操作完成。我们可以通过这样一个测试代码来直观的理解同步调用："
   ]
  },
  {
   "cell_type": "code",
   "id": "64e7361d-d646-472c-ab5c-6be9cbe97fc0",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T02:24:28.747962Z",
     "start_time": "2025-01-09T02:24:18.735182Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def call_model():\n",
    "    # 模拟同步API调用\n",
    "    print(\"开始调用模型...\")\n",
    "    time.sleep(5)  # 模拟调用等待\n",
    "    print(\"模型调用完成。\")\n",
    "\n",
    "\n",
    "def perform_other_tasks():\n",
    "    # 模拟执行其他任务\n",
    "    for i in range(5):\n",
    "        print(f\"执行其他任务 {i + 1}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    call_model()\n",
    "    perform_other_tasks()\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    return f\"总共耗时：{total_time}秒\"\n",
    "\n",
    "\n",
    "# 运行同步任务并打印完成时间\n",
    "main_time = main()\n",
    "main_time"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始调用模型...\n",
      "模型调用完成。\n",
      "执行其他任务 1\n",
      "执行其他任务 2\n",
      "执行其他任务 3\n",
      "执行其他任务 4\n",
      "执行其他任务 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'总共耗时：10.00539779663086秒'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "ff110e8d-c17f-458f-80b9-2f7ae333c984",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这段同步调用的程序先模拟了一个耗时5秒的模型调用，随后执行了五个其他任务，每个任务耗时1秒。实际的执行时间为约10.00秒。这体现了同步执行的特点：每个操作依次执行，直到当前操作完成后才开始下一个操作，从而导致总的执行时间是各个操作时间的总和。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed0760-a2e0-4d2b-978b-ca5e54d8d715",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而异步调用，允许程序在等待某些操作完成时继续执行其他任务，而不是阻塞等待。这在处理I/O操作（如网络请求、文件读写等）时特别有用，可以显著提高程序的效率和响应性。"
   ]
  },
  {
   "cell_type": "code",
   "id": "2e45600d-cd4e-4740-9641-3880d043c6cc",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T02:26:30.184064Z",
     "start_time": "2025-01-09T02:26:25.161149Z"
    }
   },
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "\n",
    "async def async_call(llm):\n",
    "    await asyncio.sleep(5)  # 模拟异步操作\n",
    "    print(\"异步调用完成\")\n",
    "\n",
    "\n",
    "async def perform_other_tasks():\n",
    "    await asyncio.sleep(5)  # 模拟异步操作\n",
    "    print(\"其他任务完成\")\n",
    "\n",
    "\n",
    "async def run_async_tasks():\n",
    "    start_time = time.time()\n",
    "    await asyncio.gather(\n",
    "        async_call(None),  # 示例调用，替换None为模拟的LLM对象\n",
    "        perform_other_tasks()\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    return f\"总共耗时：{end_time - start_time}秒\"\n",
    "\n",
    "\n",
    "# 运行异步任务并打印完成时间\n",
    "await run_async_tasks()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "异步调用完成\n",
      "其他任务完成\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'总共耗时：5.013248920440674秒'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "eb391308-3b20-4ec5-8adf-95aa8d58f7b9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;使用`asyncio.gather()`并行执行时，理想情况下，因为两个任务几乎同时开始，它们的执行时间将重叠。如果两个任务的执行时间相同（这里都是3秒），那么总执行时间应该接近单个任务的执行时间（3秒左右），而不是两者时间之和。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfa7bec-63ca-4892-92ef-65153c7ee47a",
   "metadata": {},
   "source": [
    "#### 异步调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08cd20e4-3769-4c0d-b275-11d8f72178f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages1 = [SystemMessage(content=\"你是一位乐于助人的智能小助手\"),\n",
    "             HumanMessage(content=\"请帮我介绍一下什么是机器学习\"), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb9de918-2154-49cd-b1eb-e7b535a5798b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reponse = await chat.ainvoke(messages1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "689b55c9-798b-40e4-aafe-fcee4735758b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'当然可以！机器学习是人工智能的一个子领域，它致力于研究如何让计算机系统通过数据学习并改进性能，而无需进行显式编程。简而言之，机器学习是一种让计算机系统从数据中学习和进行预测的技术。通过训练模型，计算机可以自动识别模式、做出决策和预测结果，从而实现各种任务，如图像识别、语音识别、自然语言处理等。机器学习在各个领域都有广泛的应用，是人工智能发展的核心技术之一。'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reponse.content"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "87906dd19294ff9e"
  },
  {
   "cell_type": "markdown",
   "id": "7011cd18-2d1f-4eee-bf6e-4278db760a70",
   "metadata": {},
   "source": [
    "&emsp;&emsp;通过上述描述，我们展示了在LangChain中使用LLMs类模型和Chat Model类模型的不同方法，其核心区别在于输入Prompt的格式。除此之外其他的工作可\n",
    "以直接利用统一的抽象接口，实现与模型交互的快速过程。而针对不同的模型，LangChain也提供个对应的接入方法，\n",
    "其相关说明文档地址：https://python.langchain.com/docs/integrations/chat/"
   ]
  },
  {
   "cell_type": "code",
   "id": "767c02ea-af12-4b9a-a489-2086404e624f",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-11T12:39:26.347613Z",
     "start_time": "2025-01-11T12:39:25.420438Z"
    }
   },
   "source": [
    "from langchain_community.chat_models import ChatBaichuan\n",
    "from langchain_core.messages import HumanMessage"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "cc2780a2-2723-41aa-8ecd-32cfcc979e7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:39:28.798313Z",
     "start_time": "2025-01-11T12:39:28.791463Z"
    }
   },
   "source": [
    "chat = ChatBaichuan(\n",
    "    # 这里替换成个人的有效 API KEY\n",
    "    baichuan_api_key=\"sk-cc5d4760df1a88414abe73a09702f46c\",\n",
    "    streaming=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "ea5bd8fd-8f77-478f-ba3c-265e5ca6f8d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:39:32.089863Z",
     "start_time": "2025-01-11T12:39:31.509791Z"
    }
   },
   "source": [
    "response = chat([HumanMessage(content=\"请介绍一下你自己\")])\n",
    "response"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p'c\\AppData\\Local\\Temp\\ipykernel_13676\\1108380999.py:1: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chat([HumanMessage(content=\"请介绍一下你自己\")])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error from Baichuan api response: <Response [400]>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mchat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mHumanMessage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m请介绍一下你自己\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m response\n",
      "File \u001B[1;32mD:\\PY_PJT\\ChatGLM3-main\\ChatGLM3-main\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:182\u001B[0m, in \u001B[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    180\u001B[0m     warned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    181\u001B[0m     emit_warning()\n\u001B[1;32m--> 182\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PY_PJT\\ChatGLM3-main\\ChatGLM3-main\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1017\u001B[0m, in \u001B[0;36mBaseChatModel.__call__\u001B[1;34m(self, messages, stop, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m   1009\u001B[0m \u001B[38;5;129m@deprecated\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0.1.7\u001B[39m\u001B[38;5;124m\"\u001B[39m, alternative\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minvoke\u001B[39m\u001B[38;5;124m\"\u001B[39m, removal\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1.0\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1010\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\n\u001B[0;32m   1011\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1015\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m   1016\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseMessage:\n\u001B[1;32m-> 1017\u001B[0m     generation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1018\u001B[0m \u001B[43m        \u001B[49m\u001B[43m[\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m   1019\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1020\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(generation, ChatGeneration):\n\u001B[0;32m   1021\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m generation\u001B[38;5;241m.\u001B[39mmessage\n",
      "File \u001B[1;32mD:\\PY_PJT\\ChatGLM3-main\\ChatGLM3-main\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[0;32m    641\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n\u001B[0;32m    642\u001B[0m             run_managers[i]\u001B[38;5;241m.\u001B[39mon_llm_error(e, response\u001B[38;5;241m=\u001B[39mLLMResult(generations\u001B[38;5;241m=\u001B[39m[]))\n\u001B[1;32m--> 643\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    644\u001B[0m flattened_outputs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    645\u001B[0m     LLMResult(generations\u001B[38;5;241m=\u001B[39m[res\u001B[38;5;241m.\u001B[39mgenerations], llm_output\u001B[38;5;241m=\u001B[39mres\u001B[38;5;241m.\u001B[39mllm_output)  \u001B[38;5;66;03m# type: ignore[list-item]\u001B[39;00m\n\u001B[0;32m    646\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results\n\u001B[0;32m    647\u001B[0m ]\n\u001B[0;32m    648\u001B[0m llm_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_combine_llm_outputs([res\u001B[38;5;241m.\u001B[39mllm_output \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results])\n",
      "File \u001B[1;32mD:\\PY_PJT\\ChatGLM3-main\\ChatGLM3-main\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(messages):\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    632\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m--> 633\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    634\u001B[0m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    635\u001B[0m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    636\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    637\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    638\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    639\u001B[0m         )\n\u001B[0;32m    640\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    641\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "File \u001B[1;32mD:\\PY_PJT\\ChatGLM3-main\\ChatGLM3-main\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001B[0m, in \u001B[0;36mBaseChatModel._generate_with_cache\u001B[1;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[0;32m    849\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    850\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 851\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    852\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    853\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    854\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    855\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\PY_PJT\\ChatGLM3-main\\ChatGLM3-main\\venv\\Lib\\site-packages\\langchain_community\\chat_models\\baichuan.py:458\u001B[0m, in \u001B[0;36mChatBaichuan._generate\u001B[1;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[0;32m    454\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstreaming:\n\u001B[0;32m    455\u001B[0m     stream_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream(\n\u001B[0;32m    456\u001B[0m         messages\u001B[38;5;241m=\u001B[39mmessages, stop\u001B[38;5;241m=\u001B[39mstop, run_manager\u001B[38;5;241m=\u001B[39mrun_manager, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    457\u001B[0m     )\n\u001B[1;32m--> 458\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgenerate_from_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstream_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    460\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chat(messages, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    461\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m res\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:\n",
      "File \u001B[1;32mD:\\PY_PJT\\ChatGLM3-main\\ChatGLM3-main\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:88\u001B[0m, in \u001B[0;36mgenerate_from_stream\u001B[1;34m(stream)\u001B[0m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_from_stream\u001B[39m(stream: Iterator[ChatGenerationChunk]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatResult:\n\u001B[0;32m     79\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Generate from a stream.\u001B[39;00m\n\u001B[0;32m     80\u001B[0m \n\u001B[0;32m     81\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;124;03m        ChatResult: Chat result.\u001B[39;00m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 88\u001B[0m     generation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     89\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m generation:\n\u001B[0;32m     90\u001B[0m         generation \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(stream)\n",
      "File \u001B[1;32mD:\\PY_PJT\\ChatGLM3-main\\ChatGLM3-main\\venv\\Lib\\site-packages\\langchain_community\\chat_models\\baichuan.py:475\u001B[0m, in \u001B[0;36mChatBaichuan._stream\u001B[1;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[0;32m    473\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chat(messages, stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    474\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m res\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:\n\u001B[1;32m--> 475\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError from Baichuan api response: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mres\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    476\u001B[0m default_chunk_class \u001B[38;5;241m=\u001B[39m AIMessageChunk\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m res\u001B[38;5;241m.\u001B[39miter_lines():\n",
      "\u001B[1;31mValueError\u001B[0m: Error from Baichuan api response: <Response [400]>"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04bd0bd-8788-4f33-a704-81e814278e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1fcd0c-dd73-4fe7-bc59-1ef2370b71cb",
   "metadata": {},
   "source": [
    "## 3.Model I/O之Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b27b7da-b51e-49db-8a35-f45ffb84b94e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;提示工程（Prompt Engineering）大家应该比较熟悉，这个概念是指在与大语言模型（LLMs），如GPT-3、Qwen等模型进行交互时，精心设计输入文本（即提示）的过程，以获得更精准、相关或有创造性的输出。在我们第一级学习计划中通过采用Few-Shot、Chain of Thought (CoT)等高级提示技巧，可以显著提高大模型在推理任务上的表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db70b5fb-48c2-475b-b61e-8692cb71b6ca",
   "metadata": {},
   "source": [
    "### 3.1 使用str.format语言构建模版"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff3749e-c19d-492c-9bf9-9d7689c64db3",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在LangChain的默认设置下， `PromptTemplate` 使用 Python 的 `str.format()` 方法进行模板化。\n",
    "&emsp;&emsp;Python的`str.format()`方法是一种字符串格式化的手段，允许我们在字符串中插入变量。使用这种方法，可以创建包含占位符的字符串模板，\n",
    "占位符由花括号{}标识。调用format()方法时，可以传入一个或多个参数，这些参数将被顺序替换进占位符中。str.format()提供了灵活的方式来构造字符串，\n",
    "支持多种格式化选项，包括数字格式化、对齐、填充、宽度设置等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25affe93-6cc9-4254-b57f-810a7b411a34",
   "metadata": {},
   "source": [
    "- **基本用法**"
   ]
  },
  {
   "cell_type": "code",
   "id": "944c90e5-3c02-47f9-b3e8-4fb14d4e41e8",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T02:56:29.711274Z",
     "start_time": "2025-01-09T02:56:29.707258Z"
    }
   },
   "source": [
    "# 简单示例，直接替换\n",
    "greeting = \"Hello, {}!\".format(\"Alice\")\n",
    "print(greeting)\n",
    "# 输出: Hello, Alice!"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Alice!\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "baa532f3-0471-4cd0-8e91-3553a3405cfb",
   "metadata": {
    "tags": []
   },
   "source": [
    "- **带有位置参数的用法**"
   ]
  },
  {
   "cell_type": "code",
   "id": "fba4a257-3405-45c0-ade0-f23f1d80d242",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T02:56:33.055627Z",
     "start_time": "2025-01-09T02:56:33.052198Z"
    }
   },
   "source": [
    "# 使用位置参数\n",
    "info = \"Name: {0}, Age: {1}\".format(\"Bob\", 30)\n",
    "print(info)\n",
    "# 输出: Name: Bob, Age: 30"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Bob, Age: 30\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "6cfbc36a-2828-4ae4-b533-5bc6b5b624a0",
   "metadata": {},
   "source": [
    "- **带有关键字参数的用法**"
   ]
  },
  {
   "cell_type": "code",
   "id": "9f8c3076-e147-4efd-9274-de41aa5a6a62",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T02:56:37.381916Z",
     "start_time": "2025-01-09T02:56:37.378583Z"
    }
   },
   "source": [
    "# 使用关键字参数\n",
    "info = \"Name: {name}, Age: {age}\".format(name=\"Charlie\", age=25)\n",
    "print(info)\n",
    "# 输出: Name: Charlie, Age: 25"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Charlie, Age: 25\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "29d7e318-673c-4932-822e-55c468742f47",
   "metadata": {},
   "source": [
    "- **使用字典解包的方式：**"
   ]
  },
  {
   "cell_type": "code",
   "id": "e7962b7c-36ee-4172-9f43-6b1be6d1603f",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T02:56:40.363138Z",
     "start_time": "2025-01-09T02:56:40.359273Z"
    }
   },
   "source": [
    "# 使用字典解包\n",
    "person = {\"name\": \"David\", \"age\": 40}\n",
    "info = \"Name: {name}, Age: {age}\".format(**person)\n",
    "print(info)\n",
    "# 输出: Name: David, Age: 40"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: David, Age: 40\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "9c250d3d-b183-46ca-b9aa-28548679f698",
   "metadata": {
    "tags": []
   },
   "source": [
    "&emsp;&emsp;在LangChain中，基本采用了Python的原生`str.format()`方法对输入数据进行格式化，这样在模型接收输入前，可以根据需要对数据进行预处理和结构\n",
    "化，以此来引导大模型进行更准确的推理。"
   ]
  },
  {
   "cell_type": "code",
   "id": "2b7c63d1-7fd4-43c7-bff3-b8848a09bac2",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T02:57:14.568714Z",
     "start_time": "2025-01-09T02:57:14.563036Z"
    }
   },
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"请给我一个关于{topic}的{type}解释。\"\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format(type=\"详细\", topic=\"量子力学\")\n",
    "\n",
    "prompt"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'请给我一个关于量子力学的详细解释。'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "id": "d0cc4d73-c3f0-48a5-82de-dbf19e574dc9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如上所示，可以使用`PromptTemplate`的`from_template`方法创建一个提示模板实例，这个模板包含了两个占位符：{topic} 和 {type}，这些占位\n",
    "符在实际调用时可以被实际的值替换。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3521a65-288d-4bb0-8c58-9d73d6fdd318",
   "metadata": {},
   "source": [
    "- **调用Chat Model**"
   ]
  },
  {
   "cell_type": "code",
   "id": "f7471a96-983a-468b-88c6-598180b95725",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:15:00.639130Z",
     "start_time": "2025-01-12T04:15:00.634781Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一个有帮助的AI机器人，你的名字是{name}。\"),\n",
    "        (\"human\", \"你好，最近怎么样？\"),\n",
    "        (\"ai\", \"我很好，谢谢！\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(name=\"小明\", user_input=\"你叫什么名字？\")"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "c642ee43-2bea-4f78-aedb-deb65b8765e1",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T02:57:38.046705Z",
     "start_time": "2025-01-09T02:57:38.041999Z"
    }
   },
   "source": [
    "messages"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个有帮助的AI机器人，你的名字是小明。', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='你好，最近怎么样？', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='我很好，谢谢！', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='你叫什么名字？', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03875188-a35f-47c7-92fd-834a6065e00b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['name', 'user_input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['name'], template='你是一个有帮助的AI机器人，你的名字是{name}。')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='你好，最近怎么样？')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='我很好，谢谢！')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_input'], template='{user_input}'))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb9c9a7-be1c-4019-9e20-624ff51c57ef",
   "metadata": {},
   "source": [
    "&emsp;&emsp;从输出上看，其构造函数在实例化prompt_template时，主要由两个关键参数进行指定：\n",
    "\n",
    "- input_variables：这是一个列表，包含模板中需要动态填充的变量名。这些变量名在模板字符串中以花括号（如{name}）标记。通过指定这些变量，可以在后续过程\n",
    "中动态地替换这些占位符。\n",
    "\n",
    "- template：这是定义具体提示文本的模板字符串。它可以包含静态文本和input_variables列表中指定的变量占位符。当调用format方法时，这些占位符会被实际的变\n",
    "量值替换，生成最终的提示文本。"
   ]
  },
  {
   "cell_type": "code",
   "id": "c03e6f72-840a-49b2-a507-2cba4ccef13a",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:15:09.021502Z",
     "start_time": "2025-01-12T04:15:06.751156Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# chat = ChatOpenAI(model_name=\"deepseek-chat\", api_key=api_key, base_url=api_base)\n",
    "chat = ChatOpenAI(model_name=\"gpt-4o-mini\", api_key=api_key)\n",
    "result = chat.invoke(messages)\n",
    "print(result.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我叫小明。很高兴认识你！有什么我可以帮助你的吗？\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "d3cfba43-1e5a-434b-8b54-c51518fdc491",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T03:05:45.791707Z",
     "start_time": "2025-01-09T03:05:45.788448Z"
    }
   },
   "source": [
    "messages = chat_template.format_messages(name=\"张三\", user_input=\"你要去哪里玩？\")"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "4ca7700d-8f79-474f-96df-ddf38684d283",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T03:05:52.815586Z",
     "start_time": "2025-01-09T03:05:51.332915Z"
    }
   },
   "source": [
    "result = chat.invoke(messages)\n",
    "print(result.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我最近想去云南，听说那里的风景很美，特别是丽江和大理。\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "id": "2365905d-b203-4764-996c-74dd52d7d5ee",
   "metadata": {},
   "source": [
    "### 3.2 构造Few-Shot模版"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75787ec0-381a-4fe2-8887-7efff731e32a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在LangChain中，很多的功能抽象、链路抽象本质上都是在对大模型的“涌现能力”能够应用落地的一种具体实现方法，而其推理的不稳定，在不修改模型本身参数（微调）的情况下，模型涌现能力极度依赖对模型的提示过程，即对同样一个模型，不同的提示方法将获得质量完全不同的结果。最为简单的提示工程的方法就是通过输入一些类似问题和问题答案，让模型参考学习，并在同一个prompt的末尾提出新的问题，依次提升模型的推理能力。"
   ]
  },
  {
   "cell_type": "code",
   "id": "eb5d4bb4-75a3-4f09-8c75-16a13eea7558",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T03:33:12.798144Z",
     "start_time": "2025-01-09T03:33:12.793877Z"
    }
   },
   "source": [
    "prompt_Few_shot_CoT4 = 'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？” \\\n",
    "                        A：“罗杰一开始有五个网球，又购买了两盒网球，每盒3个，共购买了6个网球，因此现在总共由5+6=11个网球。因此答案是11。” \\\n",
    "                        Q：“食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？” \\\n",
    "                        A：“食堂最初有23个苹果，用掉20个，然后又买了6个，总共有23-20+6=9个苹果，答案是9。” \\\n",
    "                        Q：“杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？” \\\n",
    "                        A：“总共有16个球，其中一半是高尔夫球，也就是8个，其中一半是蓝色的，也就是4个，答案是4个。” \\\n",
    "                        Q：“艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？” \\\n",
    "                        A：'\n",
    "\n",
    "prompt_Few_shot_CoT4"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？”                         A：“罗杰一开始有五个网球，又购买了两盒网球，每盒3个，共购买了6个网球，因此现在总共由5+6=11个网球。因此答案是11。”                         Q：“食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？”                         A：“食堂最初有23个苹果，用掉20个，然后又买了6个，总共有23-20+6=9个苹果，答案是9。”                         Q：“杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？”                         A：“总共有16个球，其中一半是高尔夫球，也就是8个，其中一半是蓝色的，也就是4个，答案是4个。”                         Q：“艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？”                         A：'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "id": "1d9aefa4-d95f-4a69-bc37-59991e1d94e8",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T03:33:16.422266Z",
     "start_time": "2025-01-09T03:33:16.419069Z"
    }
   },
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [SystemMessage(content=\"你是一个擅长数学推理的专家\"),\n",
    "            HumanMessage(\n",
    "                content=\"艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？\"), ]"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "id": "577d7d8e-8ccf-4f40-81fa-3dc510b7620c",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T03:33:33.564580Z",
     "start_time": "2025-01-09T03:33:22.075659Z"
    }
   },
   "source": [
    "resonse = chat.invoke(messages)\n",
    "resonse.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### 问题回顾\\n\\n艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？\\n\\n### 初步理解\\n\\n首先，我们需要明确几个关键点：\\n\\n1. **爬升时间**：艾米每次爬到滑梯顶部需要4分钟。\\n2. **下滑时间**：艾米每次滑下滑梯需要1分钟。\\n3. **总时间**：水滑梯将在15分钟后关闭。\\n\\n我们的目标是计算在15分钟内，艾米能完成多少次完整的“爬升+下滑”的循环。\\n\\n### 分析过程\\n\\n#### 1. 计算一个完整循环所需的时间\\n\\n一个完整的循环包括爬升和下滑两个部分：\\n\\n- 爬升时间：4分钟\\n- 下滑时间：1分钟\\n\\n因此，一个完整循环的总时间为：\\n\\n4分钟（爬升） + 1分钟（下滑） = **5分钟**\\n\\n#### 2. 计算在15分钟内可以完成多少个完整循环\\n\\n既然一个循环需要5分钟，那么在15分钟内可以完成的循环次数为：\\n\\n15分钟 ÷ 5分钟/循环 = **3次**\\n\\n#### 3. 检查是否有剩余时间\\n\\n完成3个完整循环后，总共花费的时间为：\\n\\n3循环 × 5分钟/循环 = 15分钟\\n\\n这意味着在15分钟结束时，艾米刚好完成第3次下滑，没有额外的时间进行下一次爬升。\\n\\n### 验证思路\\n\\n为了确保我们的计算正确，我们可以逐步模拟艾米的活动：\\n\\n- **第一次循环**：\\n  - 爬升：0分钟开始，4分钟结束\\n  - 下滑：4分钟开始，5分钟结束\\n\\n- **第二次循环**：\\n  - 爬升：5分钟开始，9分钟结束\\n  - 下滑：9分钟开始，10分钟结束\\n\\n- **第三次循环**：\\n  - 爬升：10分钟开始，14分钟结束\\n  - 下滑：14分钟开始，15分钟结束\\n\\n在15分钟结束时，艾米刚好完成第3次下滑，没有时间进行第4次爬升。\\n\\n### 结论\\n\\n通过上述分析和验证，我们可以确定：\\n\\n**在15分钟内，艾米可以滑3次。**\\n\\n### 最终答案\\n\\n**艾米在滑梯关闭之前可以滑3次。**\\n\\n---\\n\\n通过这个简单的数学问题，我们不仅练习了基本的加减乘除运算，还学会了如何将实际问题转化为数学模型，并通过逐步分析和验证来确保答案的准确性。这对于培养逻辑思维和解决问题的能力非常有帮助。'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "id": "e7e189cd-d018-47f3-ba08-b083d9b864fa",
   "metadata": {},
   "source": [
    "实际上，在使用GPT-3.5时，我们可以观察到，即使不采用Few-Shot提示，模型也能以很高的概率正确回答问题，这归功于模型本身已经非常强大的能力。"
   ]
  },
  {
   "cell_type": "code",
   "id": "aa9e3378-6ee6-4625-8c18-194e63fb523a",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T03:33:42.616180Z",
     "start_time": "2025-01-09T03:33:42.613261Z"
    }
   },
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "id": "795f1054-530a-4baa-88fc-0e26f3c64d4f",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T03:33:49.490766Z",
     "start_time": "2025-01-09T03:33:49.487479Z"
    }
   },
   "source": [
    "examples = [\n",
    "    {\"input\": \"罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？\",\n",
    "     \"output\": \"罗杰一开始有五个网球，又购买了两盒网球，每盒3个，共购买了6个网球，因此现在总共由5+6=11个网球。因此答案是11。\"},\n",
    "\n",
    "    {\"input\": \"食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？\",\n",
    "     \"output\": \"食堂最初有23个苹果，用掉20个，然后又买了6个，总共有23-20+6=9个苹果，答案是9。\"},\n",
    "\n",
    "    {\"input\": \"杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？\",\n",
    "     \"output\": \"总共有16个球，其中一半是高尔夫球，也就是8个，其中一半是蓝色的，也就是4个，答案是4个。\"},\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "id": "bdb2cfc0-2460-4718-a59c-e66549d9b741",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T03:33:54.141746Z",
     "start_time": "2025-01-09T03:33:54.136342Z"
    }
   },
   "source": [
    "# This is a prompt template used to format each individual example.\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.format())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？\n",
      "AI: 罗杰一开始有五个网球，又购买了两盒网球，每盒3个，共购买了6个网球，因此现在总共由5+6=11个网球。因此答案是11。\n",
      "Human: 食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？\n",
      "AI: 食堂最初有23个苹果，用掉20个，然后又买了6个，总共有23-20+6=9个苹果，答案是9。\n",
      "Human: 杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？\n",
      "AI: 总共有16个球，其中一半是高尔夫球，也就是8个，其中一半是蓝色的，也就是4个，答案是4个。\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "id": "b2fa456e-7fe3-424e-a170-4218853def8b",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T03:34:03.877999Z",
     "start_time": "2025-01-09T03:34:03.874813Z"
    }
   },
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "id": "aed82582-2059-4d88-b82d-6745d9f34910",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T03:34:05.923014Z",
     "start_time": "2025-01-09T03:34:05.918583Z"
    }
   },
   "source": [
    "final_prompt"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[FewShotChatMessagePromptTemplate(examples=[{'input': '罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？', 'output': '罗杰一开始有五个网球，又购买了两盒网球，每盒3个，共购买了6个网球，因此现在总共由5+6=11个网球。因此答案是11。'}, {'input': '食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？', 'output': '食堂最初有23个苹果，用掉20个，然后又买了6个，总共有23-20+6=9个苹果，答案是9。'}, {'input': '杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？', 'output': '总共有16个球，其中一半是高尔夫球，也就是8个，其中一半是蓝色的，也就是4个，答案是4个。'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "id": "6c46857a-cc96-4e40-9e8f-fa68fcce1b12",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T03:34:12.907404Z",
     "start_time": "2025-01-09T03:34:10.089374Z"
    }
   },
   "source": [
    "chain = final_prompt | chat\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\"input\": \"艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？\"})\n",
    "response.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'艾米每次爬上滑梯并滑下来总共需要4分钟（爬上去） + 1分钟（滑下来） = 5分钟。水滑梯将在15分钟后关闭，因此在这段时间内，艾米可以完成15分钟 / 5分钟每次 = 3次完整的上下滑梯过程。所以，在关闭之前，艾米能滑3次。'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "cell_type": "markdown",
   "id": "deb4fe3e-7486-4395-ae17-6c61920f72e1",
   "metadata": {},
   "source": [
    "### 3.3 示例选择器"
   ]
  },
  {
   "cell_type": "code",
   "id": "f3f340d2-c42a-4aac-84af-fa7b2222c059",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T03:51:03.034314Z",
     "start_time": "2025-01-12T03:51:02.336572Z"
    }
   },
   "source": [
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    # 数学推理\n",
    "    {\n",
    "        \"question\": \"小明的妈妈给了他10块钱去买文具，如果一支笔3块钱，小明最多能买几支笔？\",\n",
    "        \"answer\": \"小明有10块钱，每支笔3块钱，所以他最多能买3支笔，因为3*3=9，剩下1块钱不够再买一支笔。因此答案是3支。\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"一个篮球队有12名球员，如果教练想分成两个小组进行训练，每组需要有多少人？\",\n",
    "        \"answer\": \"篮球队总共有12名球员，分成两个小组，每组有12/2=6名球员。因此每组需要有6人。\"\n",
    "    },\n",
    "    # 逻辑推理\n",
    "    {\n",
    "        \"question\": \"如果所有的猫都怕水，而Tom是一只猫，请问Tom怕水吗？\",\n",
    "        \"answer\": \"根据题意，所有的猫都怕水，因此作为一只猫的Tom也会怕水。所以答案是肯定的，Tom怕水。\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"在夏天，如果白天温度高于30度，夜晚就会很凉爽。今天白天温度是32度，请问今晚会凉爽吗？\",\n",
    "        \"answer\": \"根据题意，只要白天温度高于30度，夜晚就会很凉爽。今天白天的温度是32度，超过了30度，因此今晚会凉爽。\"\n",
    "    },\n",
    "    # 常识问题\n",
    "    {\n",
    "        \"question\": \"地球绕太阳转一圈需要多久？\",\n",
    "        \"answer\": \"地球绕太阳转一圈大约需要365天，也就是一年的时间。\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"水的沸点是多少摄氏度？\",\n",
    "        \"answer\": \"水的沸点是100摄氏度。\"\n",
    "    },\n",
    "    # 文化常识\n",
    "    {\n",
    "        \"question\": \"中国的首都是哪里？\",\n",
    "        \"answer\": \"中国的首都是北京。\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"世界上最长的河流是哪一条？\",\n",
    "        \"answer\": \"世界上最长的河流是尼罗河。\"\n",
    "    },\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "61f15e0c-a270-4fb7-bdca-93b01b7dd177",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如上所示的示例中涵盖了数学推理、逻辑推理、常识问题以及文化常识四种不同的语义场景，并为每个场景提供了两个问题和答案。接下来将上述示例构建成提示模版"
   ]
  },
  {
   "cell_type": "code",
   "id": "9c040370-aa53-4b07-919e-a020edcd1449",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T03:35:13.569135Z",
     "start_time": "2025-01-09T03:35:13.564431Z"
    }
   },
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{question}\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.format())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 小明的妈妈给了他10块钱去买文具，如果一支笔3块钱，小明最多能买几支笔？\n",
      "AI: 小明有10块钱，每支笔3块钱，所以他最多能买3支笔，因为3*3=9，剩下1块钱不够再买一支笔。因此答案是3支。\n",
      "Human: 一个篮球队有12名球员，如果教练想分成两个小组进行训练，每组需要有多少人？\n",
      "AI: 篮球队总共有12名球员，分成两个小组，每组有12/2=6名球员。因此每组需要有6人。\n",
      "Human: 如果所有的猫都怕水，而Tom是一只猫，请问Tom怕水吗？\n",
      "AI: 根据题意，所有的猫都怕水，因此作为一只猫的Tom也会怕水。所以答案是肯定的，Tom怕水。\n",
      "Human: 在夏天，如果白天温度高于30度，夜晚就会很凉爽。今天白天温度是32度，请问今晚会凉爽吗？\n",
      "AI: 根据题意，只要白天温度高于30度，夜晚就会很凉爽。今天白天的温度是32度，超过了30度，因此今晚会凉爽。\n",
      "Human: 地球绕太阳转一圈需要多久？\n",
      "AI: 地球绕太阳转一圈大约需要365天，也就是一年的时间。\n",
      "Human: 水的沸点是多少摄氏度？\n",
      "AI: 水的沸点是100摄氏度。\n",
      "Human: 中国的首都是哪里？\n",
      "AI: 中国的首都是北京。\n",
      "Human: 世界上最长的河流是哪一条？\n",
      "AI: 世界上最长的河流是尼罗河。\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "id": "68742106-f041-4857-b438-2bc5b6eb3f64",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T03:35:19.786540Z",
     "start_time": "2025-01-09T03:35:19.782690Z"
    }
   },
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一个无所不能的人，无论什么问题都可以回答。\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "final_prompt"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='你是一个无所不能的人，无论什么问题都可以回答。'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'question': '小明的妈妈给了他10块钱去买文具，如果一支笔3块钱，小明最多能买几支笔？', 'answer': '小明有10块钱，每支笔3块钱，所以他最多能买3支笔，因为3*3=9，剩下1块钱不够再买一支笔。因此答案是3支。'}, {'question': '一个篮球队有12名球员，如果教练想分成两个小组进行训练，每组需要有多少人？', 'answer': '篮球队总共有12名球员，分成两个小组，每组有12/2=6名球员。因此每组需要有6人。'}, {'question': '如果所有的猫都怕水，而Tom是一只猫，请问Tom怕水吗？', 'answer': '根据题意，所有的猫都怕水，因此作为一只猫的Tom也会怕水。所以答案是肯定的，Tom怕水。'}, {'question': '在夏天，如果白天温度高于30度，夜晚就会很凉爽。今天白天温度是32度，请问今晚会凉爽吗？', 'answer': '根据题意，只要白天温度高于30度，夜晚就会很凉爽。今天白天的温度是32度，超过了30度，因此今晚会凉爽。'}, {'question': '地球绕太阳转一圈需要多久？', 'answer': '地球绕太阳转一圈大约需要365天，也就是一年的时间。'}, {'question': '水的沸点是多少摄氏度？', 'answer': '水的沸点是100摄氏度。'}, {'question': '中国的首都是哪里？', 'answer': '中国的首都是北京。'}, {'question': '世界上最长的河流是哪一条？', 'answer': '世界上最长的河流是尼罗河。'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['answer', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['answer'], input_types={}, partial_variables={}, template='{answer}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "id": "cb7806d9-33a0-4a62-86fd-b95c1bf133c2",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-09T03:37:17.282910Z",
     "start_time": "2025-01-09T03:37:15.986025Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\"input\": \"世界上最高的山峰是哪一座\"})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='世界上最高的山峰是珠穆朗玛峰。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 319, 'total_tokens': 329, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'prompt_cache_hit_tokens': 256, 'prompt_cache_miss_tokens': 63}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3a5770e1b4', 'finish_reason': 'stop', 'logprobs': None}, id='run-4e347aca-3b66-4da2-a044-1a46c73fa1af-0', usage_metadata={'input_tokens': 319, 'output_tokens': 10, 'total_tokens': 329, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "id": "e4ec9b58-494c-4f47-98fe-2611cdf2afb2",
   "metadata": {},
   "source": [
    "#### 上述过程，其实就对应了我们之前提到的问题，针对“世界上最高的山峰是哪一座？”这类问题，实际上只需输入与文化常识相关的提示就足够了。而如果要实现这一功能，就需要借助LangChain中的`example_selector`模块。在该模块中，有如下两个参数需要关注：\n",
    "\n",
    "- example_selector ：负责为给定输入选择少数样本（以及它们返回的顺序）。它们实现了 BaseExampleSelector 接口。一个常见的例子是向量存储支持的 SemanticSimilarityExampleSelector\n",
    "- example_prompt ：通过其 format_messages 方法将每个示例转换为 1 条或多条消息。一个常见的示例是将每个示例转换为一条人工消息和一条人工智能消息响应，或者一条人工消息后跟一条函数调用消息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0208fac2-eeaa-474d-8fed-cede9cd21700",
   "metadata": {},
   "source": [
    "#### LangChain已经内置了多个预定义的示例选择器，每种选择器都有其特定的功能和适用场景。在这个案例中，我们先以`SemanticSimilarityExampleSelector`为例进行探索。这个选择器的目的是在给定的示例集合中选出与输入在语义上最接近的示例。主要的实现步骤如下：\n",
    "\n",
    "1. **向量化表示**：首先，输入文本和示例集中的每个示例都会被转换成向量化的表示。通过Embedding模型将文本转换成高维空间中的点，其中语义上相似的文本会被映射到空间中相近的位置。\n",
    "\n",
    "2. **计算语义相似度**：一旦得到了输入和示例的向量化表示，下一步是计算输入与每个示例之间的语义相似度。通过计算向量之间的距离来实现，常见的度量方式包括余弦相似度、欧氏距离等。\n",
    "\n",
    "3. **选择最相似的示例**：基于计算出的相似度，选择一个或多个与输入最相似的示例。这个选择过程可以是简单地选取相似度最高的示例，或者根据相似度分布采取更复杂的策略，例如选择相似度高于某个阈值的所有示例。"
   ]
  },
  {
   "cell_type": "code",
   "id": "974ce6da-2887-47e9-bb0e-15e6e1628da4",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-11T13:06:44.352603Z",
     "start_time": "2025-01-11T13:06:23.903095Z"
    }
   },
   "source": [
    "# ! pip install --upgrade transformers -i https://pypi.tuna.tsinghua.edu.cn/simpl\n",
    "# ! python -m pip install --upgrade pip setuptools\n",
    "# ! pip install chroma-hnswlib -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "! pip install chromadb -i https://pypi.tuna.tsinghua.edu.cn/simple\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting chromadb\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/bb/1c/2b77093f4191ad2d1ab70b9215cb6bc9f43350aa3e9e54a44304c8379335/chromadb-0.6.2-py3-none-any.whl (606 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/84/c2/80633736cd183ee4a62107413def345f7e6e3c01563dbca1417363cf957e/build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from chromadb) (2.10.4)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/73/09/10d57569e399ce9cbc5eee2134996581c957f63a9addfa6ca657daf006b8/chroma_hnswlib-0.7.6.tar.gz (32 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: fastapi>=0.95.2 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from chromadb) (0.115.6)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/76/bd/2d550ac79443cdbb6a5a4193c37820f04df0499e1ecbe8e41c5462cf0c2d/posthog-3.7.5-py2.py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/dd/80/76979e0b744307d488c79e41051117634b956612cc731f1028eb17ee7294/onnxruntime-1.20.1-cp312-cp312-win_amd64.whl (11.3 MB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/43/53/5249ea860d417a26a3a6f1bdedfc0748c4f081a3adaec3d398bc0f7c6a71/opentelemetry_api-1.29.0-py3-none-any.whl (64 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f2/de/4b4127a25d1594851d99032f3a9acb09cb512d11edec713410fb906607f4/opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/cb/d6/37784bb30b213e2dd6838b9f96c2940907022c1b75ef1ff18a99afe42433/opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl (12 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d1/1d/512b86af21795fb463726665e2f61db77d384e8779fdcf4cb0ceec47866d/opentelemetry_sdk-1.29.0-py3-none-any.whl (118 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from chromadb) (0.21.0)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.65.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a4/ed/1f1afb2e9e7f38a545d628f864d562a5ae64fe6f7a10e28ffb9b185b4e89/importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from chromadb) (1.68.1)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/76/b9/d51d34e6cd6d887adddb28a8680a1d34235cc45b9d6e238ce39b98199ca0/bcrypt-4.2.1-cp39-abi3-win_amd64.whl (153 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from chromadb) (0.15.1)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/fb/a8/17f5e28cecdbd6d48127c22abdb794740803491f422a11905c4569d8e139/kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/66/e8/542ed252924002b84c43a68a080cfd4facbea0d5df361e4f59637638d3c7/mmh3-5.0.1-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from chromadb) (3.10.13)\n",
      "Requirement already satisfied: httpx>=0.27.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: packaging>=19.1 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/bd/24/12818598c362d7f300f18e74db45963dbcb85150324092410c8b49405e42/pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: colorama in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.41.3)\n",
      "Requirement already satisfied: anyio in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.7.0)\n",
      "Requirement already satisfied: certifi in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.37.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/3b/5d/63d4ae3b9daea098d5d6f5da83984853c1bbacd5dc826764b249fe119d24/requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/7e/80/cab10959dc1faead58dc8384a781dfbf93cb4d33d50988f7a69f1b7c9bbe/oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/4c/a3/ac312faeceffd2d8f86bc6dcb5c401188ba5a01bc88e69bed97578a0dfcd/durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/fb/b4/31c461eef98b96b8ab736d97274548eaf2b2e349bf09e4de3902f7d53084/flatbuffers-24.12.23-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: protobuf in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.2)\n",
      "Requirement already satisfied: sympy in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/1d/8f/c7f227eb42cfeaddce3eb0c96c60cbca37797fa7b34f8e1aeadf6c5c0983/Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/9e/75/7609bda3d72bf307839570b226180513e854c01443ebe265ed732a4980fc/opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/bd/66/a500e38ee322d89fce61c74bd7769c8ef3bebc6c2f43fda5f3fc3441286d/opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d2/81/0899c6b56b1023835f266d909250d439174afa0c34ed5944c5021d3da263/opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl (16 kB)\n",
      "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ff/b1/55a77152a83ec8998e520a3a575f44af1020cfe4bdc000b7538583293b85/opentelemetry_instrumentation-0.50b0-py3-none-any.whl (30 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/da/fb/dc15fad105450a015e913cfa4f5c27b6a5f1bea8fb649f8cae11e699c8af/opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl (166 kB)\n",
      "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/64/8a/9e1b54f50d1fddebbeac9a9b0632f8db6ece7add904fb593ee2e268ee4de/opentelemetry_util_http-0.50b0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/39/e3/893e8757be2612e6c266d9bb58ad2e3651524b5b40cf56761e985a28b13e/asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.27.0)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.3)\n",
      "Requirement already satisfied: websockets>=10.4 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.12.0)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/5a/dc/491b7661614ab97483abf2056be1deee4dc2490ecbf7bff9ab5cdbac86e1/pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Building wheels for collected packages: chroma-hnswlib\n",
      "  Building wheel for chroma-hnswlib (pyproject.toml): started\n",
      "  Building wheel for chroma-hnswlib (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for chroma-hnswlib: filename=chroma_hnswlib-0.7.6-cp312-cp312-win_amd64.whl size=155471 sha256=061233cf526fbe58b545c855ed4b30d4d29d55516db98797dad40636f3b174a4\n",
      "  Stored in directory: c:\\users\\p'c\\appdata\\local\\pip\\cache\\wheels\\7e\\54\\6a\\6af0f5d7f9793cdb5d7cf9c966289588b4ba8eaee0e63847db\n",
      "Successfully built chroma-hnswlib\n",
      "Installing collected packages: pypika, monotonic, flatbuffers, durationpy, pyreadline3, pyproject_hooks, opentelemetry-util-http, opentelemetry-proto, oauthlib, mmh3, importlib-resources, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, requests-oauthlib, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, humanfriendly, build, opentelemetry-semantic-conventions, kubernetes, coloredlogs, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.2 coloredlogs-15.0.1 deprecated-1.2.15 durationpy-0.9 flatbuffers-24.12.23 humanfriendly-10.0 importlib-resources-6.5.2 kubernetes-31.0.0 mmh3-5.0.1 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.20.1 opentelemetry-api-1.29.0 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-instrumentation-0.50b0 opentelemetry-instrumentation-asgi-0.50b0 opentelemetry-instrumentation-fastapi-0.50b0 opentelemetry-proto-1.29.0 opentelemetry-sdk-1.29.0 opentelemetry-semantic-conventions-0.50b0 opentelemetry-util-http-0.50b0 posthog-3.7.5 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "0ea92192-eabe-4ab3-b764-d53f5435941e",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T03:59:24.893705Z",
     "start_time": "2025-01-12T03:59:24.603674Z"
    }
   },
   "source": [
    "from langchain.prompts import SemanticSimilarityExampleSelector\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "025fbba9-d352-4e36-a8be-af3edc206aed",
   "metadata": {},
   "source": [
    "&emsp;&emsp;使用OpenAI的Embedding模型构建向量，并存储至chromadb向量数据库中。"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d41e040-92d9-44d2-a4d5-d5e11745f620",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T03:51:38.491Z",
     "start_time": "2025-01-12T03:51:38.485518Z"
    }
   },
   "source": [
    "to_vectorize = [\" \".join(example.values()) for example in examples]\n",
    "to_vectorize"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['小明的妈妈给了他10块钱去买文具，如果一支笔3块钱，小明最多能买几支笔？ 小明有10块钱，每支笔3块钱，所以他最多能买3支笔，因为3*3=9，剩下1块钱不够再买一支笔。因此答案是3支。',\n",
       " '一个篮球队有12名球员，如果教练想分成两个小组进行训练，每组需要有多少人？ 篮球队总共有12名球员，分成两个小组，每组有12/2=6名球员。因此每组需要有6人。',\n",
       " '如果所有的猫都怕水，而Tom是一只猫，请问Tom怕水吗？ 根据题意，所有的猫都怕水，因此作为一只猫的Tom也会怕水。所以答案是肯定的，Tom怕水。',\n",
       " '在夏天，如果白天温度高于30度，夜晚就会很凉爽。今天白天温度是32度，请问今晚会凉爽吗？ 根据题意，只要白天温度高于30度，夜晚就会很凉爽。今天白天的温度是32度，超过了30度，因此今晚会凉爽。',\n",
       " '地球绕太阳转一圈需要多久？ 地球绕太阳转一圈大约需要365天，也就是一年的时间。',\n",
       " '水的沸点是多少摄氏度？ 水的沸点是100摄氏度。',\n",
       " '中国的首都是哪里？ 中国的首都是北京。',\n",
       " '世界上最长的河流是哪一条？ 世界上最长的河流是尼罗河。']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "95241548-5777-42e2-b647-2e1740e13906",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:11:42.104412Z",
     "start_time": "2025-01-12T04:11:42.075035Z"
    }
   },
   "source": [
    "from langchain_core.embeddings import DeterministicFakeEmbedding\n",
    "\n",
    "# api_base = \"https://newone.nxykj.tech/v1\"\n",
    "# api_key = \"sk-5693c407c9774742b633d28163d8fcc7\"\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=api_key)\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", api_key=api_key)\n",
    "embeddings = DeterministicFakeEmbedding(size=4096)\n",
    "vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c6b9659b57a95653"
  },
  {
   "cell_type": "markdown",
   "id": "91794d6d-5ae2-4aff-a2b6-a911fbcd1c6d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;创建完矢量存储后，接下来需要创建 example_selector 。可以通过`k`参数指定获取多少个与输入问题最相关的示例。这里我们选择2。"
   ]
  },
  {
   "cell_type": "code",
   "id": "bedb316c-8fe4-47d1-88be-d2e54ef2266d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:11:54.244413Z",
     "start_time": "2025-01-12T04:11:54.236209Z"
    }
   },
   "source": [
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vectorstore,\n",
    "    k=2,\n",
    ")\n",
    "\n",
    "example_selector.select_examples({\"input\": \"内蒙古的省会是哪里\"})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': '地球绕太阳转一圈大约需要365天，也就是一年的时间。', 'question': '地球绕太阳转一圈需要多久？'},\n",
       " {'answer': '篮球队总共有12名球员，分成两个小组，每组有12/2=6名球员。因此每组需要有6人。',\n",
       "  'question': '一个篮球队有12名球员，如果教练想分成两个小组进行训练，每组需要有多少人？'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "65a788c5-01d6-438c-992f-bcf549b7bfc0",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:12:19.807253Z",
     "start_time": "2025-01-12T04:12:19.799311Z"
    }
   },
   "source": [
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vectorstore,\n",
    "    k=2,\n",
    ")\n",
    "\n",
    "example_selector.select_examples({\"input\": \"罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？\"})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': '篮球队总共有12名球员，分成两个小组，每组有12/2=6名球员。因此每组需要有6人。',\n",
       "  'question': '一个篮球队有12名球员，如果教练想分成两个小组进行训练，每组需要有多少人？'},\n",
       " {'answer': '地球绕太阳转一圈大约需要365天，也就是一年的时间。', 'question': '地球绕太阳转一圈需要多久？'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "10600ece-5eb3-46f8-ad79-48607bbafb9d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;从上面两个示例我们观察到，在处理基于文化常识的查询时（例如，询问“内蒙古的省会是哪里？”），选定的few-shot模板会来源自文化常识类别。相反，当遇到需要推理的问题时，则倾向于选择我们预先定义好的数学推理类提示示例。这种动态匹配策略展示了利用语义相似性选择器在大语言模型中进行精准模板选择的能力，从而有效地应对不同类别的查询，确保模型输出的相关性和准确性。"
   ]
  },
  {
   "cell_type": "code",
   "id": "87f2b878-c9eb-415b-ad5d-f8dc4445b866",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:12:54.005371Z",
     "start_time": "2025-01-12T04:12:54.001272Z"
    }
   },
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "# 创建一个 FewShotChatMessagePromptTemplate 对象\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    input_variables=[\"input\"],  # 定义输入变量的列表\n",
    "    example_selector=example_selector,  # 使用动态的示例选择器\n",
    "\n",
    "    # 定义每一轮对话的格式化文本\n",
    "    example_prompt=ChatPromptTemplate.from_messages(\n",
    "        [(\"human\", \"{question}\"), (\"ai\", \"{answer}\")]\n",
    "    ),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "46bcc405-eb7b-4d83-b80f-fa098cf6b242",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:12:56.435992Z",
     "start_time": "2025-01-12T04:12:56.431593Z"
    }
   },
   "source": [
    "few_shot_prompt"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FewShotChatMessagePromptTemplate(example_selector=SemanticSimilarityExampleSelector(vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000000004EE9460>, k=2, example_keys=None, input_keys=None, vectorstore_kwargs=None), input_variables=['input'], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['answer', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['answer'], input_types={}, partial_variables={}, template='{answer}'), additional_kwargs={})]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "9e556284-eaa3-46c0-a1d1-e69cc64d5a65",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:13:04.896561Z",
     "start_time": "2025-01-12T04:13:04.888750Z"
    }
   },
   "source": [
    "print(few_shot_prompt.format(input=\"罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 一个篮球队有12名球员，如果教练想分成两个小组进行训练，每组需要有多少人？\n",
      "AI: 篮球队总共有12名球员，分成两个小组，每组有12/2=6名球员。因此每组需要有6人。\n",
      "Human: 地球绕太阳转一圈需要多久？\n",
      "AI: 地球绕太阳转一圈大约需要365天，也就是一年的时间。\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "4e05451b-a7b1-423e-8fc7-efa5a512c698",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:13:13.061133Z",
     "start_time": "2025-01-12T04:13:13.053746Z"
    }
   },
   "source": [
    "print(few_shot_prompt.format(input=\"月亮每天什么时候出现\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 地球绕太阳转一圈需要多久？\n",
      "AI: 地球绕太阳转一圈大约需要365天，也就是一年的时间。\n",
      "Human: 世界上最长的河流是哪一条？\n",
      "AI: 世界上最长的河流是尼罗河。\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "1a07a7db-f2d2-42b7-bb70-4343517d1773",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:13:25.820891Z",
     "start_time": "2025-01-12T04:13:25.817345Z"
    }
   },
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一个无所不能的人，无论什么问题都可以回答。\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "07d5c4eb-9bfb-46fd-ad38-c89324d84380",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:13:27.231451Z",
     "start_time": "2025-01-12T04:13:27.227263Z"
    }
   },
   "source": [
    "final_prompt"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='你是一个无所不能的人，无论什么问题都可以回答。'), additional_kwargs={}), FewShotChatMessagePromptTemplate(example_selector=SemanticSimilarityExampleSelector(vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000000004EE9460>, k=2, example_keys=None, input_keys=None, vectorstore_kwargs=None), input_variables=['input'], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['answer', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['answer'], input_types={}, partial_variables={}, template='{answer}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "b4ed41bc-7403-4f08-beed-b63f32857db5",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:15:31.872262Z",
     "start_time": "2025-01-12T04:15:29.158165Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\"input\": \"月亮每天什么时候出现\"})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='月亮的出现时间并不是固定的，它会根据月相和地球与月球的相对位置而变化。通常情况下，月亮在日落后升起，但具体时间会随着月份和月相的变化而有所不同。例如，满月时月亮大约在日落时升起，而新月时则在日出时升起。一般来说，月亮的升起时间会在每晚推迟约50分钟。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 98, 'prompt_tokens': 96, 'total_tokens': 194, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-80683e43-2110-4a5e-84da-39c1ce2ccd8b-0', usage_metadata={'input_tokens': 96, 'output_tokens': 98, 'total_tokens': 194, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "29d2de8a-ad4a-4cfb-9e54-b3070fe10359",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:15:44.901639Z",
     "start_time": "2025-01-12T04:15:42.735737Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "response = chain.invoke({\"input\": \"内蒙的省会是哪座城市？\"})"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "86aeec08-2704-461d-9a54-888fdfb4eaba",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:15:48.181647Z",
     "start_time": "2025-01-12T04:15:48.177358Z"
    }
   },
   "source": [
    "response"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='内蒙古自治区的省会是呼和浩特。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 138, 'total_tokens': 150, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'stop', 'logprobs': None}, id='run-f7d66152-75c7-4cb5-8374-d4d653c8368c-0', usage_metadata={'input_tokens': 138, 'output_tokens': 12, 'total_tokens': 150, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "68c001e2-5554-4615-b0a8-3a3195f7278c",
   "metadata": {},
   "source": [
    "#### 通过对`SemanticSimilarityExampleSelector`的应用，我们展示了如何动态地选择适合各种输入提示的示例模板。在LangChain框架中，示例选择器的功能和作用依赖于其具体的定义和实现。我们使用的`SemanticSimilarityExampleSelector`示例选择器，该过程涉及到示例的向量化表示、相似度计算和返回Tok这样的流程。到目前为止，LangChain已经定义了以下四种示例选择器，每种都有其独特的选择机制：\n",
    "\n",
    "1. **Similarity**：基于输入与示例之间的语义相似度来选择示例。这种方法通过比较语义内容的接近程度来确定最相关的示例。\n",
    "\n",
    "2. **MMR (Maximum Margin Relevance)** : 根据输入与示例之间的最大边际相关性来挑选示例。这种方法旨在平衡相关性和多样性，通过选择既相关又能提供新信息的示例。\n",
    "\n",
    "3. **Length**：依据指定长度内能够容纳的示例数量来进行选择。这个方法简单直接，特别适用于需要控制输出长度的场景。\n",
    "\n",
    "4. **Ngram**：通过计算输入与示例之间的n-gram重叠来选择示例。这种方法重视文本表面的匹配度，适用于需要精确文本匹配的情境。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fdb73a-7660-444a-9072-34a8b3635d54",
   "metadata": {},
   "source": [
    "### 3.4 自定义示例选择器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f70e71-2398-450b-9093-172728401185",
   "metadata": {},
   "source": [
    "&emsp;&emsp;LangChain的`ExampleSelector`模块封装了一系列较为通用的示例选择器，例如我们上一小节使用的`SemanticSimilarityExampleSelector`，它能够基于语义相似度来选择最相关示例的，已经能够满足多数提示示例使用场景的需求。然而，现实中根据不同的业务需求，可能会遇到这些通用选择器无法完全满足特定需求的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf42540-cb5d-43e3-8614-ba04034b7c40",
   "metadata": {
    "tags": []
   },
   "source": [
    "&emsp;&emsp;在LangChain中，`Example Selector`的基本接口定义如下：\n",
    "\n",
    "```python\n",
    "    class BaseExampleSelector(ABC):\n",
    "        \"\"\"用于选择要包含在提示中的示例的接口。\"\"\"\n",
    "\n",
    "        @abstractmethod\n",
    "        def select_examples(self, input_variables: Dict[str, str]) -> List[dict]:\n",
    "            \"\"\"根据输入选择使用哪些示例。\"\"\"\n",
    "\n",
    "        @abstractmethod\n",
    "        def add_example(self, example: Dict[str, str]) -> Any:\n",
    "            \"\"\"向存储中添加新的示例。\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fafe5c-35d6-4b70-ac0a-7d2c550d48e9",
   "metadata": {},
   "source": [
    "> ABC，全称为“Abstract Base Class”（抽象基类），是Python中abc模块的一部分。在 Python 中，抽象基类用于定义其他类必须遵循的基本接口或蓝图，但不能直接实例化。其主要目的是为了提供一种形式化的方式来定义和检查子类的接口。抽象基类中，可以定义抽象方法，它没有实现（也就是说，它没有方法体）。任何继承该抽象基类的子类都必须提供这些抽象方法的实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c155c5f-8b22-4e8c-ab1a-cb4d6d41bc8b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;从上述基本接口来看，它需要定义的唯一方法是 `select_examples` 方法，其接受输入变量，然后返回示例列表。如何选择这些示例取决于每个具体的实现，也就是我们自定义的逻辑。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12428d7-6bf3-4b87-87a3-f913cbd264b0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;为了演示示例选择器的自定义过程，我们设计这样一个简单的场景：聊天机器人的回答选择器。在这个场景中，聊天机器人需要根据用户的输入从一个预设的回答库中选择最合适的回答。这个预设库包含了多个输入-回答对，机器人的任务是找到与用户输入在长度上最接近的问题，然后返回相应的预设回答。通过这种方法来可以帮助机器人处理未知或罕见的用户输入，通过匹配相近长度的问题来给出一个看似合适的回答，增加用户满意度。"
   ]
  },
  {
   "cell_type": "code",
   "id": "0bace8ca-046a-4795-a151-f3c721c95367",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:16:45.504307Z",
     "start_time": "2025-01-12T04:16:45.501541Z"
    }
   },
   "source": [
    "examples = [\n",
    "    {\"input\": \"你好吗？\", \"output\": \"我很好，谢谢！你呢？\"},\n",
    "    {\"input\": \"你是谁？\", \"output\": \"我是一个聊天机器人。\"},\n",
    "    {\"input\": \"你能做什么？\", \"output\": \"我可以回答简单的问题，比如现在的时间或天气。\"},\n",
    "    {\"input\": \"现在几点了？\", \"output\": \"抱歉，我无法提供实时信息。\"},\n",
    "    {\"input\": \"你喜欢音乐吗？\", \"output\": \"我不能听音乐，但我可以帮你找到音乐信息。\"},\n",
    "    {\"input\": \"告诉我一些关于中国的事情。\", \"output\": \"中国是一个拥有悠久历史和丰富文化的国家。\"},\n",
    "    {\"input\": \"最近有什么好玩的电影吗？\", \"output\": \"我不太清楚当前的电影信息，但我推荐你查看电影推荐网站。\"},\n",
    "    {\"input\": \"你能帮我学习编程吗？\", \"output\": \"当然，我可以提供一些学习资源和编程练习。\"}\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "7692af27-c0bc-42d5-b533-0b628cc2ffbe",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这个examples列表包含了几个不同长度的问题及其对应的答案。根据聊天机器人的回答选择器的需求设定，我们设计的示例选择器功能就应该是：当用户输入一段文本时，自定义示例选择器的的`select_examples`方法会根据输入的长度选择一个最接近的问题，并返回那个问题的答案。这样，即使用户的问题没有直接出现在预设的问题列表中，聊天机器人也能提供一个相关的回答。"
   ]
  },
  {
   "cell_type": "code",
   "id": "bb7b4268-f515-4054-bf45-b258ab175902",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:17:05.489949Z",
     "start_time": "2025-01-12T04:17:05.485503Z"
    }
   },
   "source": [
    "from langchain_core.example_selectors.base import BaseExampleSelector\n",
    "\n",
    "\n",
    "class ChatbotExampleSelector(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        # examples是一个列表，包含多个字典，每个字典都有'input'和'output'键\n",
    "        self.examples = examples\n",
    "\n",
    "    def add_example(self, example):\n",
    "        # 向examples列表添加一个输入-输出对\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        # 此方法找到与用户输入长度最接近的示例，并返回相应的输出\n",
    "        new_word = input_variables[\"input\"]\n",
    "        new_word_length = len(new_word)\n",
    "\n",
    "        best_match = None\n",
    "        ## 声明一个无穷大的变量\n",
    "        smallest_diff = float(\"inf\")\n",
    "\n",
    "        for example in self.examples:\n",
    "            current_diff = abs(len(example[\"input\"]) - new_word_length)\n",
    "\n",
    "            if current_diff < smallest_diff:\n",
    "                smallest_diff = current_diff\n",
    "                best_match = example\n",
    "\n",
    "        # 如果找到了最佳匹配项，返回相应的输出；否则，返回None\n",
    "        return [best_match] if best_match else []\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "08287c98-644f-4856-8aa4-6250134ba670",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:17:11.862778Z",
     "start_time": "2025-01-12T04:17:11.858581Z"
    }
   },
   "source": [
    "example_selector = ChatbotExampleSelector(examples)\n",
    "example_selector"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ChatbotExampleSelector at 0x4ee8d40>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "77d27283-33cd-497e-bff5-875a284ca160",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:17:16.323750Z",
     "start_time": "2025-01-12T04:17:16.319544Z"
    }
   },
   "source": [
    "example_selector.select_examples({\"input\": \"你好呀。\"})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': '你好吗？', 'output': '我很好，谢谢！你呢？'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "1711154b-8b96-498c-8cb3-55ddd64057db",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:17:20.055051Z",
     "start_time": "2025-01-12T04:17:20.050221Z"
    }
   },
   "source": [
    "example_selector.select_examples({\"input\": \"我特别的喜欢打篮球\"})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': '你能帮我学习编程吗？', 'output': '当然，我可以提供一些学习资源和编程练习。'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "c0e60ebb-4675-4fd8-af6d-ac9f34754c25",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:17:22.150393Z",
     "start_time": "2025-01-12T04:17:22.146314Z"
    }
   },
   "source": [
    "example_selector.select_examples({\"input\": \"今天的天气很好，能推荐一个好玩的去处吗？\"})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': '告诉我一些关于中国的事情。', 'output': '中国是一个拥有悠久历史和丰富文化的国家。'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "3aa74c4f-ebed-45d7-9539-e3605e7cb763",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:17:23.393649Z",
     "start_time": "2025-01-12T04:17:23.389713Z"
    }
   },
   "source": [
    "example_selector.select_examples({\"input\": \"今天的天气很好，非常适合春游，能帮我推荐一个适合全家人出游的好去处吗？\"})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': '告诉我一些关于中国的事情。', 'output': '中国是一个拥有悠久历史和丰富文化的国家。'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "fd287d5d-b176-4755-ae26-b7a03aa7459a",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:17:26.265987Z",
     "start_time": "2025-01-12T04:17:26.263334Z"
    }
   },
   "source": [
    "example_selector.add_example({\"input\": \"春天到了，大家都喜欢出去春游，但是很多地方并不是很好，请问有推荐码？\",\n",
    "                              \"output\": \"如果你喜欢春天春游的话，你可以去一些国家公园，景色非常好。\"})"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "id": "272dcec4-d5ee-4a40-9669-ed1fddb00619",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:17:27.577628Z",
     "start_time": "2025-01-12T04:17:27.573218Z"
    }
   },
   "source": [
    "example_selector.select_examples({\"input\": \"今天的天气很好，非常适合春游，能帮我推荐一个适合全家人出游的好去处吗？\"})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': '春天到了，大家都喜欢出去春游，但是很多地方并不是很好，请问有推荐码？',\n",
       "  'output': '如果你喜欢春天春游的话，你可以去一些国家公园，景色非常好。'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "735c78e2-5539-4587-a582-9c088cdaa386",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这里就可以匹配到最新添加的提示模版了。而对接大模型推理过程就和常规的使用方式无异。首先在对话模版中接入`ChatbotExampleSelector`示例选择器，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "id": "534a0005-5fe7-4506-8a7f-4c82f0479cd2",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:18:15.186185Z",
     "start_time": "2025-01-12T04:18:15.182285Z"
    }
   },
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "# 创建一个 FewShotChatMessagePromptTemplate 对象\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    input_variables=[\"input\"],  # 定义输入变量的列表\n",
    "    example_selector=example_selector,  # 使用动态的示例选择器\n",
    "\n",
    "    # 定义每一轮对话的格式化文本\n",
    "    example_prompt=ChatPromptTemplate.from_messages(\n",
    "        [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n",
    "    ),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "126a911d-2a1d-4dec-a4bb-9e08506309c0",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:18:16.723773Z",
     "start_time": "2025-01-12T04:18:16.719975Z"
    }
   },
   "source": [
    "print(few_shot_prompt.format(input=\"今天的天气很好，非常适合春游，能帮我推荐一个适合全家人出游的好去处吗？\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 春天到了，大家都喜欢出去春游，但是很多地方并不是很好，请问有推荐码？\n",
      "AI: 如果你喜欢春天春游的话，你可以去一些国家公园，景色非常好。\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "82b07709-a6be-4215-9283-a5e9b87359a6",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:18:23.230688Z",
     "start_time": "2025-01-12T04:18:23.226954Z"
    }
   },
   "source": [
    "print(few_shot_prompt.format(input=\"你好呀。\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 你好吗？\n",
      "AI: 我很好，谢谢！你呢？\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "0cd5ac44-6805-4583-899e-33acb9dd11cd",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:18:28.921166Z",
     "start_time": "2025-01-12T04:18:28.917938Z"
    }
   },
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一个无所不能的人，无论什么问题都可以回答。\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "8dbdcc37-050b-4f56-817e-d7c418e08e6e",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:18:29.886675Z",
     "start_time": "2025-01-12T04:18:29.882905Z"
    }
   },
   "source": [
    "final_prompt"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='你是一个无所不能的人，无论什么问题都可以回答。'), additional_kwargs={}), FewShotChatMessagePromptTemplate(example_selector=<__main__.ChatbotExampleSelector object at 0x0000000004EE8D40>, input_variables=['input'], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "96d9938a-9eb6-4df4-83d6-933ab5424886",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:18:37.154582Z",
     "start_time": "2025-01-12T04:18:36.020728Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\"input\": \"你好呀\"})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！有什么我可以帮你的吗？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 46, 'total_tokens': 56, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-0ca98e85-2ed6-4535-aefb-d2a469969590-0', usage_metadata={'input_tokens': 46, 'output_tokens': 10, 'total_tokens': 56, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "07da6bfe-2e8a-4508-8f10-23ad7498cfd3",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:18:51.383747Z",
     "start_time": "2025-01-12T04:18:50.034850Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\"input\": \"你是谁？\"})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我是一个人工智能助手，旨在回答你的问题和提供信息。有什么我可以帮助你的吗？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 47, 'total_tokens': 70, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-b5714592-fbec-48c3-9146-4d8deef028a1-0', usage_metadata={'input_tokens': 47, 'output_tokens': 23, 'total_tokens': 70, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "59e8a24f-2c21-46e2-9ea4-35e519d425c1",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:19:02.784148Z",
     "start_time": "2025-01-12T04:18:58.496757Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "response = chain.invoke({\"input\": \"今天的天气很好，非常适合春游，能帮我推荐一个适合全家人出游的好去处吗？\"})\n",
    "response.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'当然可以！以下是几个适合全家春游的好去处：\\n\\n1. **公园或植物园**：许多城市都有美丽的城市公园或植物园，春天时花开得特别美丽，非常适合全家一起散步、野餐和拍照。\\n\\n2. **国家公园**：如果你喜欢大自然，可以选择附近的国家公园，进行徒步旅行、观鸟或野餐，享受新鲜的空气和美丽的风景。\\n\\n3. **海滩**：如果你住在靠近海边的地方，春天的海滩通常人少、风景美，可以玩沙、捡贝壳，或者简单地享受阳光。\\n\\n4. **农场游**：许多地方的农场会在春天开放，提供采摘水果、喂动物等活动，适合家庭一起体验。\\n\\n5. **历史遗址或博物馆**：如果你对历史感兴趣，可以选择参观当地的历史遗址或博物馆，既能增长知识，又能享受家庭时光。\\n\\n选择一个适合你们的地方，尽情享受春游的乐趣吧！'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "id": "ce923e17-02cb-4805-bf35-f367199dc88e",
   "metadata": {},
   "source": [
    "## 4.  Model I/O之Output Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46503cf-8ce6-41af-915e-8e5d934a1ab5",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Output Parsers，即输出解析器，这个概念非常好理解，就是负责获取大模型的输出并将其转换为更合适的格式。这在应用开发中及其重要。在大多数复杂应用场景中，处理逻辑往往环环相扣，执行某项业务逻辑可能需要多次调用大模型，其中上一次的调用结果将被用于指导下一次调用的逻辑。在这种情况下，结构化的信息会比纯文本又有价值，同时这也是输出解析器的价值所在。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d603fce-322b-4e5d-9ea5-ac228e2672e9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;LangChain构造的输出解释器必须实现两个主要方法：\n",
    "- Get format instructions：该方法会返回一个字符串，其中包含有关如何格式化语言模型输出的指令。\n",
    "- Parse：该方法会接收字符串，并将其解析为某种结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d44c0-3129-425e-92e4-1aacbe4a5938",
   "metadata": {},
   "source": [
    "&emsp;&emsp;目前已经支持的解析格式已经包括Json、Xml、Csv以及OpenAI的Tools和Functions等多种格式，具体可看：https://python.langchain.com/docs/modules/model_io/output_parsers/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e553dc1b-1a0f-42c8-824f-71a6882a351f",
   "metadata": {},
   "source": [
    "### Datetime parser"
   ]
  },
  {
   "cell_type": "code",
   "id": "5fd75642-0d24-4901-af64-3e1ae2b2e1ec",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:19:45.827755Z",
     "start_time": "2025-01-12T04:19:45.699992Z"
    }
   },
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "output_parser = DatetimeOutputParser()"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "id": "f046a631-d10b-4eb5-8b9c-4afe7f90146c",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:19:48.314439Z",
     "start_time": "2025-01-12T04:19:48.309982Z"
    }
   },
   "source": [
    "output_parser.get_format_instructions()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 1903-09-02T00:48:50.841522Z, 0633-10-10T12:56:43.090096Z, 0300-04-12T11:40:40.417864Z\\n\\nReturn ONLY this string, no other words!\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "aac62edf-0873-4098-bb03-7b2754d9704f",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:20:01.314150Z",
     "start_time": "2025-01-12T04:20:01.311347Z"
    }
   },
   "source": [
    "template = \"\"\"用户发起的提问:\n",
    "\n",
    "{question}\n",
    "\n",
    "{format_instructions}\"\"\"\n"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "id": "555bcc32-2fed-480c-bc53-924ead3552ad",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:20:16.814254Z",
     "start_time": "2025-01-12T04:20:16.811342Z"
    }
   },
   "source": [
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template,\n",
    "    # 预定义的变量，这里我们传入格式化指令\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "id": "c5c620c5-5fef-466c-9c9a-e190d03a28e2",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:23:18.288190Z",
     "start_time": "2025-01-12T04:23:18.283124Z"
    }
   },
   "source": [
    "prompt"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], input_types={}, partial_variables={'format_instructions': \"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 1518-03-23T15:05:48.617378Z, 0468-03-03T15:08:49.288752Z, 0294-04-07T14:02:25.795084Z\\n\\nReturn ONLY this string, no other words!\"}, template='用户发起的提问:\\n\\n{question}\\n\\n{format_instructions}')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "id": "37658faf-1730-493c-9de0-6379c92880f2",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:20:36.297947Z",
     "start_time": "2025-01-12T04:20:36.295389Z"
    }
   },
   "source": [
    "\n",
    "chain = prompt | chat | output_parser"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "id": "85228251-9209-4511-a26e-7f12da8f78ec",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:23:35.230511Z",
     "start_time": "2025-01-12T04:23:33.987780Z"
    }
   },
   "source": [
    "output = chain.invoke({\"question\": \"你好，请问你叫什么？\"})\n",
    "output\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 10, 3, 12, 45, 30, 123456)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "id": "b3dd9693-c06f-44dd-ac16-2b42c89b3fd1",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-12T04:23:37.085400Z",
     "start_time": "2025-01-12T04:23:37.082331Z"
    }
   },
   "source": [
    "print(output)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-03 12:45:30.123456\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "id": "d174a3d5-16d4-4059-81cc-a146fa2e9763",
   "metadata": {},
   "source": [
    "### JSON parser"
   ]
  },
  {
   "cell_type": "code",
   "id": "23ef566b-ede0-4343-b6e6-c9b814098883",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-13T09:21:33.489770Z",
     "start_time": "2025-01-13T09:21:33.487125Z"
    }
   },
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic.v1 import BaseModel, Field  # 使用 v1 兼容命名空间\n",
    "from langchain_openai import ChatOpenAI\n",
    "from openai import OpenAI\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "e21a684a-fc19-405e-abef-e9673ca15cc3",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-13T09:19:48.225737Z",
     "start_time": "2025-01-13T09:19:48.220631Z"
    }
   },
   "source": [
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "62a5a123-8157-42d1-8024-4b98814a7361",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-13T09:22:14.481368Z",
     "start_time": "2025-01-13T09:22:11.202613Z"
    }
   },
   "source": [
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-4o-mini\", api_key=api_key)\n",
    "\n",
    "chain = prompt | chat | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't scientists trust atoms?\",\n",
       " 'punchline': 'Because they make up everything!'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "9ccbf602-e873-4067-912d-1d5098f6680a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T09:23:04.638774Z",
     "start_time": "2025-01-13T09:23:04.634487Z"
    }
   },
   "source": "parser.get_format_instructions()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"question to set up a joke\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"answer to resolve the joke\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\\n```'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "798e7985-8425-419c-b8e8-2504651aedbb",
   "metadata": {},
   "source": [
    "## 5. Ollama项目"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3076270a-55ac-454f-9155-136c273162f9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Ollama是在Github上的一个开源项目，其项目定位是：**一个本地运行大模型的集成框架**，目前主要针对主流的LLaMA架构的开源大模型设计，通过将模型权重、配置文件和必要数据封装进由`Modelfile`定义的包中，从而实现大模型的下载、启动和本地运行的自动化部署及推理流程。此外，Ollama内置了一系列针对大模型运行和推理的优化策略，目前作为一个非常热门的大模型托管平台，已被包括LangChain、Taskweaver等在内的多个热门项目高度集成。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6003d521-7cb7-470b-ba0b-a66e36ca1746",
   "metadata": {},
   "source": [
    "> Ollama官方地址：https://ollama.com/\n",
    "\n",
    "> Ollama Github开源地址：https://github.com/ollama/ollama\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd19d21d-7b5c-45d5-8531-1ae9aabae10b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Ollama项目支持跨平台部署，目前已兼容Mac、Linux和Windows操作系统。特别地对于Windows用户提供了非常直观的预览版，包括了内置的GPU加速功能、访问完整模型库的能力，以及对OpenAI的兼容性在内的Ollama API，使其对Windows用户尤为友好。而无论在使用哪个操作系统中，Ollama项目的安装过程都设计得非常简单。根据后续的课程的研发需求，我们还是选择以Linux版本为例进行详细介绍。对于其他操作系统版本的安装，大家可以通过如下链接，根据自己的实际情况进行安装体验：\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d670db5-6397-4f1f-b89c-4fdf7519a71b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;一键安装的过程极为简便，仅需通过执行以下命令行即可自动化完成：\n",
    "```bash\n",
    "    sudo apt-get update\n",
    "    sudo apt-get install pciutils lshw\n",
    "    \n",
    "    curl -fsSL https://ollama.com/install.sh | sh\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c80a5b4-0d68-47e1-af68-eb39e0f85985",
   "metadata": {},
   "source": [
    "\n",
    "&emsp;&emsp;这行命令的目的是从`https://ollama.com/` 网站读取 `install.sh` 脚本，并立即通过 `sh` 执行该脚本，在安装过程中会包含以下几个主要的操作：\n",
    "1. 检查当前服务器的基础环境，如系统版本等；\n",
    "2. 下载Ollama的二进制文件；\n",
    "3. 配置系统服务，包括创建用户和用户组，添加Ollama的配置信息；\n",
    "4. 启动Ollama服务；\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc53098e-9c8a-4ae4-9bc5-345615dae57e",
   "metadata": {},
   "source": [
    "## 6. LangChain调用私有模型"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T06:03:35.648373Z",
     "start_time": "2025-01-18T06:03:34.358789Z"
    }
   },
   "cell_type": "code",
   "source": "! ollama pull deepseek-coder",
   "id": "7b2ac5b164217cd8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[?25lpulling manifest 鉅� \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest 鉅� \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest 鉅� \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest 鉅� \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest 鉅� \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest 鉅� \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest 鉅� \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest 鉅� \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest 鉅� \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest 鉅� \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest 鉅� \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest 鉅� \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest \n",
      "pulling d040cc185215... 100% 鈻曗枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枏 776 MB                         \n",
      "pulling a3a0e9449cb6... 100% 鈻曗枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枏  13 KB                         \n",
      "pulling 8893e08fa9f9... 100% 鈻曗枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枏   59 B                         \n",
      "pulling 8972a96b8ff1... 100% 鈻曗枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枏  297 B                         \n",
      "pulling d55c9eb1669a... 100% 鈻曗枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枅鈻堚枏  483 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001B[?25h\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "a6efed38-3c66-40ca-ae77-789c927db945",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:00:19.832132Z",
     "start_time": "2025-01-18T06:00:19.828901Z"
    }
   },
   "source": [
    "from langchain_community.chat_models import ChatOllama"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "75233225-66f7-4b06-85e7-183e1016aea1",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:00:31.430574Z",
     "start_time": "2025-01-18T06:00:31.427817Z"
    }
   },
   "source": [
    "# ollama_llm = ChatOllama(model=\"qwen:0.5b-chat\")\n",
    "ollama_llm = ChatOllama(model=\"deepseek-coder\")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "31425ab1-2896-4f10-9392-c10154391f9b",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:03:48.688271Z",
     "start_time": "2025-01-18T06:03:48.684422Z"
    }
   },
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"你好，请你介绍一下你自己\",\n",
    "    )\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "b0671039",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:03:54.906369Z",
     "start_time": "2025-01-18T06:03:51.346353Z"
    }
   },
   "source": [
    "chat_model_response = ollama_llm.invoke(messages)\n",
    "\n",
    "chat_model_response"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='对不起，作为一个AI编程助手，我并没有实际的自我意识或身份。我是基于Deepseek公司的深度求索（DeepSeek Coder）模型训练出来的智能系统程序，专门为解决计算机科学相关的问题提供帮助和解答方案。我的主要目标是协助用户在他们的编程问题上寻求有效的答案、快速的理解并有效地回答他们可能遇到的不确定性或困惑的地方。\\n', additional_kwargs={}, response_metadata={'model': 'deepseek-coder', 'created_at': '2025-01-18T06:03:54.9022059Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 1505267000, 'load_duration': 825912300, 'prompt_eval_count': 78, 'prompt_eval_duration': 207000000, 'eval_count': 100, 'eval_duration': 394000000}, id='run-453b4932-ae50-443c-aedb-fd4e788a36f9-0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "a3501a56-7492-4c4c-bff0-8ec22ed5f0b1",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:04:34.626732Z",
     "start_time": "2025-01-18T06:04:34.621426Z"
    }
   },
   "source": [
    "chat_model_response.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'对不起，作为一个AI编程助手，我并没有实际的自我意识或身份。我是基于Deepseek公司的深度求索（DeepSeek Coder）模型训练出来的智能系统程序，专门为解决计算机科学相关的问题提供帮助和解答方案。我的主要目标是协助用户在他们的编程问题上寻求有效的答案、快速的理解并有效地回答他们可能遇到的不确定性或困惑的地方。\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "357ab5e0",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:04:45.270248Z",
     "start_time": "2025-01-18T06:04:45.266234Z"
    }
   },
   "source": [
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"请问什么是机器学习?\",\n",
    "    )\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "7843b54b",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:04:48.915510Z",
     "start_time": "2025-01-18T06:04:46.140690Z"
    }
   },
   "source": [
    "chat_model_response = ollama_llm.invoke(messages)\n",
    "\n",
    "chat_model_response"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' Machine Learning (ML) 是指计算机科学和信息技术领域中的一门特殊学科。它主要研究如何让计算机系统通过经验或记忆来改善其性能，而无需进行显式编程即可执行此类任务的概念理解、算法设计以及实现这些能力的过程中的过程化方法论（特别是统计学习理论的基础上所建立的方法和技术如决策树等结构模型）。\\n', additional_kwargs={}, response_metadata={'model': 'deepseek-coder', 'created_at': '2025-01-18T06:04:48.9123279Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 722278900, 'load_duration': 4413700, 'prompt_eval_count': 76, 'prompt_eval_duration': 18000000, 'eval_count': 92, 'eval_duration': 697000000}, id='run-b714b9e3-a1c9-49f1-a98a-d6fb2dee8d94-0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "1723ec5b",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:05:09.745745Z",
     "start_time": "2025-01-18T06:05:09.741580Z"
    }
   },
   "source": [
    "chat_model_response.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Machine Learning (ML) 是指计算机科学和信息技术领域中的一门特殊学科。它主要研究如何让计算机系统通过经验或记忆来改善其性能，而无需进行显式编程即可执行此类任务的概念理解、算法设计以及实现这些能力的过程中的过程化方法论（特别是统计学习理论的基础上所建立的方法和技术如决策树等结构模型）。\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "263ca98c",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:06:26.175082Z",
     "start_time": "2025-01-18T06:06:25.996860Z"
    }
   },
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "# 构建模版\n",
    "template = \"你是一个有用的助手，可以将{input_language}翻译成{output_language}。\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "# 生成对话形式的聊天信息格式\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "chat_prompt"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input_language', 'output_language', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input_language', 'output_language'], input_types={}, partial_variables={}, template='你是一个有用的助手，可以将{input_language}翻译成{output_language}。'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "086ebb37",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:06:30.040222Z",
     "start_time": "2025-01-18T06:06:30.036143Z"
    }
   },
   "source": [
    "# 格式化变量输入\n",
    "messages = chat_prompt.format_messages(input_language=\"java\", output_language=\"python\", text=\"我爱编程\")\n",
    "messages"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个有用的助手，可以将中文翻译成英语。', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='我爱编程', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "ab19c4b2",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:07:17.840363Z",
     "start_time": "2025-01-18T06:07:15.176070Z"
    }
   },
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# 实例化Ollama启动的模型\n",
    "# ollama_llm = ChatOllama(model=\"qwen:0.5b-chat\")\n",
    "ollama_llm = ChatOllama(model=\"deepseek-coder\")\n",
    "\n",
    "# 执行推理\n",
    "result = ollama_llm.invoke(messages)\n",
    "print(result.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是的！作为一个人工智能程序，我的设计目标就是帮助用户理解和解决各种类型的技术问题、困惑或者挑战（包括但不限于Python, Java或C++等常见语言中的特定错误信息以及如何在不同的平台上有效地使用不同软件库来实现您的需求的情况。我可以指导您进行编程，提供代码示例并解释复杂的概念以便更好理解！\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "d0490e5a",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:09:21.809684Z",
     "start_time": "2025-01-18T06:09:21.804580Z"
    }
   },
   "source": [
    "# 格式化变量输入\n",
    "messages = chat_prompt.format_messages(input_language=\"java\", output_language=\"python\", text=\"我喜欢java\")\n",
    "messages"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个有用的助手，可以将java翻译成python。', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='我喜欢java', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "a6dd865b-f4c7-431a-b31e-863fa656f560",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:09:29.691973Z",
     "start_time": "2025-01-18T06:09:26.930805Z"
    }
   },
   "source": [
    "# 执行推理\n",
    "result = ollama_llm.invoke(messages)\n",
    "print(result.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然！Java 是一种编程语言，它以其强健的面向对象特性而闻名于世，并提供了许多高级功能来简化任务和解决复杂问题的方式（例如多线程、垃圾回收等）。此外，由于 Java 是静态类型的，所以在执行过程中无法更改变量的类型或声明函数的返回值数据类型以供调用者使用时会出现错误信息提示警告或者异常终止程序运行等等优点来满足开发者的需求和期望。\n",
      "\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "076506ba-28b0-4e15-b43c-410a1508dd4b",
   "metadata": {},
   "source": [
    "## 7. LangChain调用外部函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65413e14-4294-4fb5-9fec-6e7f6f8cffa0",
   "metadata": {},
   "source": [
    "### 7.1 大模型调用外部函数"
   ]
  },
  {
   "cell_type": "code",
   "id": "2ee32c6e-a372-403a-aacc-e3b0e8dd4c33",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T10:42:04.212410Z",
     "start_time": "2025-01-19T10:42:03.913107Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import io\n",
    "import inspect\n",
    "import requests"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "5f4d2672-3765-40f5-bebf-47dcfd352a9e",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T06:51:00.186299Z",
     "start_time": "2025-01-19T06:51:00.183143Z"
    }
   },
   "source": "open_weather_key = \"ca673e17d804b89c0d70b56855cb88a9\"",
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "id": "3b4d3cff-3f55-4b6d-ba72-d876352f347d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:16:55.223594Z",
     "start_time": "2025-01-18T06:16:55.106620Z"
    }
   },
   "source": [
    "import requests\n",
    "\n",
    "# Step 1.构建请求\n",
    "url = \"https://api.open.geovisearth.com/v2/cn/area/basic\"\n",
    "\n",
    "# Step 2.设置查询参数\n",
    "# params = {\n",
    "#     \"q\": \"Beijing\",  # 查询北京实时天气\n",
    "#     \"appid\": open_weather_key,  # 注意：这里需要替换为实际的 OpenWeather API key\n",
    "#     \"units\": \"metric\",  # 使用摄氏度而不是华氏度\n",
    "#     \"lang\": \"zh_cn\"  # 输出语言为简体中文\n",
    "# }\n",
    "\n",
    "params = {\n",
    "    \"location\": \"WTX_CH101020100\",\n",
    "    # \"location\": loc,\n",
    "    \"token\": open_weather_key  # 输入API key\n",
    "}\n",
    "\n",
    "# Step 3.发送GET请求\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "# Step 4.解析响应\n",
    "data = response.json()\n",
    "# return json.dumps(data,ensure_ascii=False)\n",
    "\n",
    "\n",
    "# Step 3.发送GET请求\n",
    "# response = requests.get(url, params=params)\n",
    "\n",
    "# Step 4.解析响应\n",
    "# data = response.json()"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "00f68907-eb65-4792-8b8d-8a5dac1b0e27",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:17:00.243855Z",
     "start_time": "2025-01-18T06:17:00.239271Z"
    }
   },
   "source": [
    "data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': {'timeZone': 'Asia/Shanghai', 'time': '20250118141701'},\n",
       " 'result': {'wd_desc': '西北风',\n",
       "  'prs': 1021.9,\n",
       "  'rh': 19,\n",
       "  'ws_desc': '1级',\n",
       "  'wp': '晴',\n",
       "  'tem': 12.4,\n",
       "  'wp_code': '00'},\n",
       " 'location': {'path': '上海市,上海', 'areaCode': 'WTX_CH101020100'},\n",
       " 'version': 'v1',\n",
       " 'status': 0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "68a3d9ed-6c97-4492-8c65-914fec628b37",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:18:45.409744Z",
     "start_time": "2025-01-18T06:18:45.404594Z"
    }
   },
   "source": [
    "# 即时温度最高、最低气温\n",
    "# data['main']['temp_min'], data['main']['temp_max']\n",
    "# 温度和气压\n",
    "data['result']['tem'], data['result']['prs']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.4, 1021.9)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "8c13c0e6-f088-4aa9-b9c5-9657e392ca75",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:19:27.968646Z",
     "start_time": "2025-01-18T06:19:27.964421Z"
    }
   },
   "source": [
    "# 天气状况\n",
    "# data['weather'][0]['description']\n",
    "data['result']['wp']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'晴'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "3344c272-add7-441e-b1be-69c8e29bba18",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T06:23:22.281482Z",
     "start_time": "2025-01-18T06:23:22.277384Z"
    }
   },
   "source": [
    "def get_weather(loc):\n",
    "    \"\"\"\n",
    "    查询即时天气函数\n",
    "    :param loc: 必要参数，字符串类型，用于表示查询天气的具体城市编码，\\\n",
    "    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入'WTX_CH101010100'；\n",
    "    :return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.open.geovisearth.com/v2/cn/area/basic\\\n",
    "    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息\n",
    "    \"\"\"\n",
    "    # Step 1.构建请求 \n",
    "    # url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "    # open_weather_key = \"49a2251ca9f1fc16bcaf80a2abc11dc8\"\n",
    "    # url = \"https://api.open.geovisearth.com/v2/cn/area/basic\"\n",
    "    # Step 2.设置查询参数\n",
    "    params1 = {\n",
    "        # \"q\": loc,\n",
    "        # \"appid\": open_weather_key,  # 输入API key\n",
    "        # \"units\": \"metric\",  # 使用摄氏度而不是华氏度\n",
    "        # \"lang\": \"zh_cn\"  # 输出语言为简体中文\n",
    "        \"location\": loc,\n",
    "        \"token\": open_weather_key  # 输入API key\n",
    "    }\n",
    "\n",
    "    # Step 3.发送GET请求\n",
    "    response1 = requests.get(url, params=params1)\n",
    "\n",
    "    # Step 4.解析响应\n",
    "    data1 = response1.json()\n",
    "    return json.dumps(data)"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "bf6c34c0-130e-4737-9ec5-29ac022d307a",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T09:03:56.724176Z",
     "start_time": "2025-01-18T09:03:56.638643Z"
    }
   },
   "source": [
    "# get_weather('ShangHai')\n",
    "# get_weather('WTX_CH101020100')\n",
    "get_weather('WTX_CH101201107')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"date\": {\"timeZone\": \"Asia/Shanghai\", \"time\": \"20250118141701\"}, \"result\": {\"wd_desc\": \"\\\\u897f\\\\u5317\\\\u98ce\", \"prs\": 1021.9, \"rh\": 19, \"ws_desc\": \"1\\\\u7ea7\", \"wp\": \"\\\\u6674\", \"tem\": 12.4, \"wp_code\": \"00\"}, \"location\": {\"path\": \"\\\\u4e0a\\\\u6d77\\\\u5e02,\\\\u4e0a\\\\u6d77\", \"areaCode\": \"WTX_CH101020100\"}, \"version\": \"v1\", \"status\": 0}'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "id": "a2c7e1b2-d962-404e-9222-c2582454c40d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T07:50:51.736508Z",
     "start_time": "2025-01-18T07:50:51.624724Z"
    }
   },
   "source": [
    "# get_weather('Beijing')\n",
    "get_weather('WTX_CH101010100')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"date\": {\"timeZone\": \"Asia/Shanghai\", \"time\": \"20250118141701\"}, \"result\": {\"wd_desc\": \"\\\\u897f\\\\u5317\\\\u98ce\", \"prs\": 1021.9, \"rh\": 19, \"ws_desc\": \"1\\\\u7ea7\", \"wp\": \"\\\\u6674\", \"tem\": 12.4, \"wp_code\": \"00\"}, \"location\": {\"path\": \"\\\\u4e0a\\\\u6d77\\\\u5e02,\\\\u4e0a\\\\u6d77\", \"areaCode\": \"WTX_CH101020100\"}, \"version\": \"v1\", \"status\": 0}'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T07:47:31.062299Z",
     "start_time": "2025-01-18T07:47:30.713455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_city_data():\n",
    "    \"\"\"\n",
    "    加载本地的XLSX文件，并提取“城市编码”和“城市”这两个列。\n",
    "\n",
    "\n",
    "    返回:\n",
    "    pd.DataFrame: 包含“城市编码”和“城市”两列的数据框。\n",
    "    \"\"\"\n",
    "    file_path = 'areaV1.0.xlsx'\n",
    "    # 读取XLSX文件\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # 提取“城市编码”和“城市”两列\n",
    "    city_data = df[['城市编码', '区县']]\n",
    "\n",
    "    return city_data\n",
    "\n",
    "\n",
    "# 示例用法\n",
    "# file_path = 'areaV1.0.xlsx'\n",
    "city_data = load_city_data()\n",
    "print(city_data)\n"
   ],
   "id": "cd4bfc6d99808863",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 城市编码   区县\n",
      "0     WTX_CH101010900   丰台\n",
      "1     WTX_CH101011000  石景山\n",
      "2     WTX_CH101011400  门头沟\n",
      "3     WTX_CH101011200   房山\n",
      "4     WTX_CH101010600   通州\n",
      "...               ...  ...\n",
      "3382  WTX_CH101341701  屏东县\n",
      "3383  WTX_CH101341801  台东县\n",
      "3384  WTX_CH101341901  花莲县\n",
      "3385  WTX_CH101342001  澎湖县\n",
      "3386  WTX_CH101340701   基隆\n",
      "\n",
      "[3387 rows x 2 columns]\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T07:47:36.904027Z",
     "start_time": "2025-01-18T07:47:36.901246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_city_mapping():\n",
    "    \"\"\"\n",
    "    创建城市名称到城市编码的映射字典。\n",
    "\n",
    "    返回:\n",
    "    dict: 城市名称到城市编码的映射字典。\n",
    "    \"\"\"\n",
    "    city_data = load_city_data()\n",
    "    city_mapping = dict(zip(city_data['区县'], city_data['城市编码']))\n",
    "    return city_mapping"
   ],
   "id": "9d2e2551d284c7b6",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T07:47:39.831618Z",
     "start_time": "2025-01-18T07:47:39.828470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_city_code(city_name):\n",
    "    \"\"\"\n",
    "    根据城市名称获取城市编码。\n",
    "\n",
    "    参数:\n",
    "    city_name (str): 城市名称。\n",
    "\n",
    "    返回:\n",
    "    str: 城市编码，如果城市名称不存在则返回None。\n",
    "    \"\"\"\n",
    "    city_mapping = create_city_mapping()\n",
    "    return city_mapping.get(city_name)"
   ],
   "id": "c55ee1f005399488",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c59d502977a7217c"
  },
  {
   "cell_type": "code",
   "id": "51477af6-2a2e-471e-9cee-58fdcd7a8a37",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T07:37:46.564016Z",
     "start_time": "2025-01-18T07:37:46.367766Z"
    }
   },
   "source": [
    "import openai\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import io\n",
    "from openai import OpenAI\n",
    "import inspect\n",
    "\n",
    "# 这里使用DeepSeek的model为deepseek-chat\n",
    "# api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "# api_base = \"https://newone.nxykj.tech/v1\"\n",
    "api_base = \"https://api.deepseek.com\"\n",
    "client = OpenAI(api_key=api_key, base_url=api_base)"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "60c2ac6d-d0be-4c39-a098-a783b498306b",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T07:39:17.123570Z",
     "start_time": "2025-01-18T07:39:17.118032Z"
    }
   },
   "source": [
    "def auto_functions(functions_list):\n",
    "    \"\"\"\n",
    "    Chat模型的functions参数编写函数\n",
    "    :param functions_list: 包含一个或者多个函数对象的列表；\n",
    "    :return：满足Chat模型functions参数要求的functions对象\n",
    "    \"\"\"\n",
    "\n",
    "    def functions_generate(functions_list):\n",
    "        # 创建空列表，用于保存每个函数的描述字典\n",
    "        functions = []\n",
    "        # 对每个外部函数进行循环\n",
    "        for function in functions_list:\n",
    "            # 读取函数对象的函数说明\n",
    "            function_description = inspect.getdoc(function)\n",
    "            # 读取函数的函数名字符串\n",
    "            function_name = function.__name__\n",
    "\n",
    "            system_prompt = '以下是某的函数说明：%s' % function_description\n",
    "            user_prompt = '根据这个函数的函数说明，请帮我创建一个JSON格式的字典，这个字典有如下5点要求：\\\n",
    "                           1.字典总共有三个键值对；\\\n",
    "                           2.第一个键值对的Key是字符串name，value是该函数的名字：%s，也是字符串；\\\n",
    "                           3.第二个键值对的Key是字符串description，value是该函数的函数的功能说明，也是字符串；\\\n",
    "                           4.第三个键值对的Key是字符串parameters，value是一个JSON Schema对象，用于说明该函数的参数输入规范。\\\n",
    "                           5.输出结果必须是一个JSON格式的字典，只输出这个字典即可，前后不需要任何前后修饰或说明的语句' % function_name\n",
    "\n",
    "            response = client.chat.completions.create(\n",
    "                # model=\"deepseek-coder\",\n",
    "                model=\"deepseek-chat\",\n",
    "                # model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ]\n",
    "            )\n",
    "            json_function_description = json.loads(\n",
    "                response.choices[0].message.content.replace(\"```\", \"\").replace(\"json\", \"\"))\n",
    "            json_str = {\"type\": \"function\", \"function\": json_function_description}\n",
    "            functions.append(json_str)\n",
    "        return functions\n",
    "\n",
    "    ## 最大可以尝试4次\n",
    "    max_attempts = 4\n",
    "    attempts = 0\n",
    "\n",
    "    while attempts < max_attempts:\n",
    "        try:\n",
    "            functions = functions_generate(functions_list)\n",
    "            break  # 如果代码成功执行，跳出循环\n",
    "        except Exception as e:\n",
    "            attempts += 1  # 增加尝试次数\n",
    "            print(\"发生错误：\", e)\n",
    "            if attempts == max_attempts:\n",
    "                print(\"已达到最大尝试次数，程序终止。\")\n",
    "                raise  # 重新引发最后一个异常\n",
    "            else:\n",
    "                print(\"正在重新运行...\")\n",
    "    return functions"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "d7858c93-a296-42d7-94e0-e9c837ccecbc",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T07:47:50.002784Z",
     "start_time": "2025-01-18T07:47:49.998828Z"
    }
   },
   "source": [
    "functions_list = [get_weather, get_city_code]\n",
    "functions_list"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function __main__.get_weather(loc)>,\n",
       " <function __main__.get_city_code(city_name)>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "id": "3519c073-95e5-483f-8627-478cf0b5de63",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T07:48:01.658043Z",
     "start_time": "2025-01-18T07:47:55.801115Z"
    }
   },
   "source": [
    "functions = auto_functions(functions_list)\n",
    "functions"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'get_weather',\n",
       "   'description': '查询即时天气函数，返回OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather，返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息。',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'loc': {'type': 'string',\n",
       "      'description': \"必要参数，字符串类型，用于表示查询天气的具体城市名称，注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入'Beijing'。\"}},\n",
       "    'required': ['loc']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'get_city_code',\n",
       "   'description': '根据城市名称获取城市编码。',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'city_name': {'type': 'string', 'description': '城市名称。'}},\n",
       "    'required': ['city_name']}}}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bca8c18214cc8f74"
  },
  {
   "cell_type": "code",
   "id": "5baf9bff-098b-4e4a-b86e-407851018446",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T09:01:22.940919Z",
     "start_time": "2025-01-18T09:01:22.935203Z"
    }
   },
   "source": [
    "def run_conversation(messages, functions_list=None, model=\"deepseek-chat\"):\n",
    "    # def run_conversation(messages, functions_list=None, model=\"deepseek-coder\"):\n",
    "    \"\"\"\n",
    "    能够自动执行外部函数调用的对话模型\n",
    "    :param messages: 必要参数，字典类型，输入到Chat模型的messages参数对象\n",
    "    :param functions_list: 可选参数，默认为None，可以设置为包含全部外部函数的列表对象\n",
    "    :param model: Chat模型，可选参数，默认模型为deepseek-coder\n",
    "    :return：Chat模型输出结果\n",
    "    \"\"\"\n",
    "    # 如果没有外部函数库，则执行普通的对话任务\n",
    "    if functions_list == None:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "        )\n",
    "        response_message = response.choices[0].message\n",
    "        final_response = response_message.content\n",
    "\n",
    "    # 若存在外部函数库，则需要灵活选取外部函数并进行回答\n",
    "    else:\n",
    "        # 创建functions对象\n",
    "        tools = auto_functions(functions_list)\n",
    "\n",
    "        # 创建外部函数库字典\n",
    "        available_functions = {func.__name__: func for func in functions_list}\n",
    "\n",
    "        # 第一次调用大模型\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\", )\n",
    "        response_message = response.choices[0].message\n",
    "\n",
    "        tool_calls = response_message.tool_calls\n",
    "\n",
    "        if tool_calls:\n",
    "\n",
    "            messages.append(response_message)\n",
    "            for tool_call in tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_to_call = available_functions[function_name]\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                ## 真正执行外部函数的就是这儿的代码\n",
    "                function_response = function_to_call(**function_args)\n",
    "                messages.append(\n",
    "                    {\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"role\": \"tool\",\n",
    "                        \"name\": function_name,\n",
    "                        \"content\": function_response,\n",
    "                    }\n",
    "                )\n",
    "                ## 第二次调用模型\n",
    "            second_response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "            )\n",
    "            # 获取最终结果\n",
    "            final_response = second_response.choices[0].message.content\n",
    "        else:\n",
    "            final_response = response_message.content\n",
    "\n",
    "    return final_response"
   ],
   "outputs": [],
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "id": "a10f74ed-3d6a-4ee7-8d2e-a498db2ff49a",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T09:01:25.202956Z",
     "start_time": "2025-01-18T09:01:25.199778Z"
    }
   },
   "source": "functions_list = [get_weather]",
   "outputs": [],
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "id": "01f9fab2-ccdb-4c77-b06f-887e4e7d4043",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T09:05:40.289752Z",
     "start_time": "2025-01-18T09:05:32.538394Z"
    }
   },
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"你是一个 helpful 的助手。\"},\n",
    "    {\"role\": \"user\", \"content\": '今天广州的天气如何？'}\n",
    "]\n",
    "\n",
    "run_conversation(messages=messages,\n",
    "                 functions_list=functions_list,\n",
    "                 )"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'今天广州的天气是晴天，气温为12.4°C，西北风1级，相对湿度为19%，气压为1021.9百帕。'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T09:07:33.575412Z",
     "start_time": "2025-01-18T09:07:33.496167Z"
    }
   },
   "cell_type": "code",
   "source": "get_weather(\"WTX_CH101280101\")",
   "id": "f33eefdd107dcb6f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"date\": {\"timeZone\": \"Asia/Shanghai\", \"time\": \"20250118141701\"}, \"result\": {\"wd_desc\": \"\\\\u897f\\\\u5317\\\\u98ce\", \"prs\": 1021.9, \"rh\": 19, \"ws_desc\": \"1\\\\u7ea7\", \"wp\": \"\\\\u6674\", \"tem\": 12.4, \"wp_code\": \"00\"}, \"location\": {\"path\": \"\\\\u4e0a\\\\u6d77\\\\u5e02,\\\\u4e0a\\\\u6d77\", \"areaCode\": \"WTX_CH101020100\"}, \"version\": \"v1\", \"status\": 0}'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "id": "984d93f5-18e7-4c2d-ba47-074cf16427a4",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T07:42:11.849210Z",
     "start_time": "2025-01-18T07:42:11.844704Z"
    }
   },
   "source": [
    "def chat_with_model(functions_list=None,\n",
    "                    prompt=\"你好呀\",\n",
    "                    model=\"deepseek-chat\",\n",
    "                    # model=\"gpt-4o-mini\",\n",
    "                    system_message=[{\"role\": \"system\", \"content\": \"你是以为乐于助人的助手。\"}]):\n",
    "    messages = system_message\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    while True:\n",
    "        answer = run_conversation(messages=messages,\n",
    "                                  functions_list=functions_list,\n",
    "                                  model=model)\n",
    "\n",
    "        print(f\"模型回答: {answer}\")\n",
    "\n",
    "        # 询问用户是否还有其他问题\n",
    "        user_input = input(\"您还有其他问题吗？(输入退出以结束对话): \")\n",
    "        if user_input == \"退出\":\n",
    "            break\n",
    "\n",
    "        # 记录用户回答\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "id": "bde16ef7-b3c0-4101-b074-02884d4cb560",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-18T07:43:20.403916Z",
     "start_time": "2025-01-18T07:43:15.273052Z"
    }
   },
   "source": [
    "chat_with_model(functions_list, prompt=\"你好\")"
   ],
   "outputs": [
    {
     "ename": "UnprocessableEntityError",
     "evalue": "Failed to deserialize the JSON body into the target type: messages[4]: invalid type: null, expected a string at line 1 column 496",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnprocessableEntityError\u001B[0m                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[58], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mchat_with_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunctions_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m你好\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[56], line 10\u001B[0m, in \u001B[0;36mchat_with_model\u001B[1;34m(functions_list, prompt, model, system_message)\u001B[0m\n\u001B[0;32m      7\u001B[0m messages\u001B[38;5;241m.\u001B[39mappend({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: prompt})\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m---> 10\u001B[0m     answer \u001B[38;5;241m=\u001B[39m \u001B[43mrun_conversation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mfunctions_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunctions_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m模型回答: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00manswer\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;66;03m# 询问用户是否还有其他问题\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[53], line 28\u001B[0m, in \u001B[0;36mrun_conversation\u001B[1;34m(messages, functions_list, model)\u001B[0m\n\u001B[0;32m     25\u001B[0m available_functions \u001B[38;5;241m=\u001B[39m {func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m: func \u001B[38;5;28;01mfor\u001B[39;00m func \u001B[38;5;129;01min\u001B[39;00m functions_list}\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# 第一次调用大模型\u001B[39;00m\n\u001B[1;32m---> 28\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompletions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     29\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     30\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtools\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     32\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mauto\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     33\u001B[0m response_message \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mchoices[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmessage\n\u001B[0;32m     35\u001B[0m tool_calls \u001B[38;5;241m=\u001B[39m response_message\u001B[38;5;241m.\u001B[39mtool_calls\n",
      "File \u001B[1;32mD:\\PY_PJT\\ChatGLM3-main\\ChatGLM3-main\\venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:275\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    273\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    274\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[1;32m--> 275\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PY_PJT\\ChatGLM3-main\\ChatGLM3-main\\venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:859\u001B[0m, in \u001B[0;36mCompletions.create\u001B[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[0;32m    817\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    818\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[0;32m    819\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    856\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[0;32m    857\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[0;32m    858\u001B[0m     validate_response_format(response_format)\n\u001B[1;32m--> 859\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    860\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/chat/completions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    861\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m    863\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    864\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    865\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43maudio\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    866\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrequency_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    867\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunction_call\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    868\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunctions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    869\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogit_bias\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    870\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    871\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_completion_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_completion_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    872\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    873\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    874\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodalities\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodalities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    875\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mparallel_tool_calls\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpresence_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreasoning_effort\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_effort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    880\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresponse_format\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    881\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    882\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mservice_tier\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    883\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstop\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    884\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    885\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    886\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    887\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtemperature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    888\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtool_choice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    889\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtools\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    890\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_logprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    891\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_p\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    892\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    893\u001B[0m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    894\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletionCreateParams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    895\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    896\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    897\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[0;32m    898\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    899\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    900\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    901\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    902\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PY_PJT\\ChatGLM3-main\\ChatGLM3-main\\venv\\Lib\\site-packages\\openai\\_base_client.py:1280\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1266\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[0;32m   1267\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1268\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1275\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1276\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m   1277\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[0;32m   1278\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[0;32m   1279\u001B[0m     )\n\u001B[1;32m-> 1280\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32mD:\\PY_PJT\\ChatGLM3-main\\ChatGLM3-main\\venv\\Lib\\site-packages\\openai\\_base_client.py:957\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    954\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    955\u001B[0m     retries_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m--> 957\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    958\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    959\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    960\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    961\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    962\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries_taken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    963\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PY_PJT\\ChatGLM3-main\\ChatGLM3-main\\venv\\Lib\\site-packages\\openai\\_base_client.py:1061\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1058\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m   1060\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1061\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1063\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[0;32m   1064\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[0;32m   1065\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1069\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[0;32m   1070\u001B[0m )\n",
      "\u001B[1;31mUnprocessableEntityError\u001B[0m: Failed to deserialize the JSON body into the target type: messages[4]: invalid type: null, expected a string at line 1 column 496"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "id": "63b598cc-5294-4004-b8e7-d46d9a7c19c1",
   "metadata": {},
   "source": [
    "### 7.2 LangChain调用外部函数"
   ]
  },
  {
   "cell_type": "code",
   "id": "c8841e75-7a7f-4121-8ceb-c9208589d906",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T09:06:04.281773Z",
     "start_time": "2025-01-19T09:06:04.277236Z"
    }
   },
   "source": [
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "import requests"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "746d3494-3175-44e5-8e88-3b820811bfcb",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T05:44:45.464818Z",
     "start_time": "2025-01-19T05:44:45.457685Z"
    }
   },
   "source": [
    "@tool\n",
    "def get_weather(loc):\n",
    "    \"\"\"\n",
    "    查询即时天气函数\n",
    "    :param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，\\\n",
    "    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入'Beijing'；\n",
    "    :return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather\\\n",
    "    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息\n",
    "    \"\"\"\n",
    "    # Step 1.构建请求\n",
    "    url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "\n",
    "    # Step 2.设置查询参数\n",
    "    params = {\n",
    "        \"q\": loc,\n",
    "        \"appid\": \"ca673e17d804b89c0d70b56855cb88a9\",  # 输入API key\n",
    "        \"units\": \"metric\",  # 使用摄氏度而不是华氏度\n",
    "        \"lang\": \"zh_cn\"  # 输出语言为简体中文\n",
    "    }\n",
    "\n",
    "    # Step 3.发送GET请求\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    # Step 4.解析响应\n",
    "    data = response.json()\n",
    "    return json.dumps(data)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "7d0a26d9-e82f-4b68-b4b7-e62025bc7070",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T05:44:50.785413Z",
     "start_time": "2025-01-19T05:44:50.779335Z"
    }
   },
   "source": [
    "get_weather"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='get_weather', description=\"查询即时天气函数\\n:param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入'Beijing'；\\n:return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息\", args_schema=<class 'langchain_core.utils.pydantic.get_weather'>, func=<function get_weather at 0x000000000B08A660>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "0f953aeb-792b-49f7-8411-f7c5d4bdd73f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如上所示，使用`@tool`装饰器可以直接将`get_weather`函数转换成工具，这个工具可以用来执行调用，并处理返回的结果。同时，可以支持一些内部方法的调用。"
   ]
  },
  {
   "cell_type": "code",
   "id": "aef14ef8-f3b9-4fc5-bc6f-b5b6bd8dd355",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T05:45:02.304049Z",
     "start_time": "2025-01-19T05:45:02.299334Z"
    }
   },
   "source": [
    "print(get_weather.name)\n",
    "print(get_weather.description)\n",
    "print(get_weather.args)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_weather\n",
      "查询即时天气函数\n",
      ":param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入'Beijing'；\n",
      ":return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息\n",
      "{'loc': {'title': 'Loc'}}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "37dd17e9-a89b-4a88-b6e2-42e32c3326a1",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T05:47:33.163622Z",
     "start_time": "2025-01-19T05:47:32.243409Z"
    }
   },
   "source": [
    "get_weather.invoke({\"loc\": \"Beijing\"})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"coord\": {\"lon\": 116.3972, \"lat\": 39.9075}, \"weather\": [{\"id\": 800, \"main\": \"Clear\", \"description\": \"\\\\u6674\", \"icon\": \"01d\"}], \"base\": \"stations\", \"main\": {\"temp\": 9.94, \"feels_like\": 8.32, \"temp_min\": 9.94, \"temp_max\": 9.94, \"pressure\": 1020, \"humidity\": 18, \"sea_level\": 1020, \"grnd_level\": 1015}, \"visibility\": 10000, \"wind\": {\"speed\": 3.21, \"deg\": 360, \"gust\": 4.79}, \"clouds\": {\"all\": 1}, \"dt\": 1737265610, \"sys\": {\"type\": 1, \"id\": 9609, \"country\": \"CN\", \"sunrise\": 1737243141, \"sunset\": 1737278242}, \"timezone\": 28800, \"id\": 1816670, \"name\": \"Beijing\", \"cod\": 200}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "9f95478a-6657-4597-8668-064a3535f35d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T05:50:53.835742Z",
     "start_time": "2025-01-19T05:50:53.829570Z"
    }
   },
   "source": [
    "llm_with_tools = chat.bind_tools([get_weather])\n",
    "llm_with_tools"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000000024C97C80>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000000024C97DD0>, root_client=<openai.OpenAI object at 0x0000000000D0E5A0>, root_async_client=<openai.AsyncOpenAI object at 0x0000000024C97CE0>, model_name='deepseek-chat', model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.deepseek.com'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'get_weather', 'description': \"查询即时天气函数\\n:param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入'Beijing'；\\n:return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息\", 'parameters': {'properties': {'loc': {}}, 'required': ['loc'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "4d9bc002-ea06-439b-8d80-8d1e39f0bd53",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T05:51:01.228691Z",
     "start_time": "2025-01-19T05:50:59.756890Z"
    }
   },
   "source": [
    "llm_with_tools.invoke(\"北京的天气怎么样？\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0_7b91ad21-70ff-4896-8309-a070c9a52e19', 'function': {'arguments': '{\"loc\":\"Beijing\"}', 'name': 'get_weather'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 199, 'total_tokens': 218, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 199}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3a5770e1b4', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-845c47ed-6b94-43ac-a4ca-e18c94fd1426-0', tool_calls=[{'name': 'get_weather', 'args': {'loc': 'Beijing'}, 'id': 'call_0_7b91ad21-70ff-4896-8309-a070c9a52e19', 'type': 'tool_call'}], usage_metadata={'input_tokens': 199, 'output_tokens': 19, 'total_tokens': 218, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "c39dee4b-e41d-4969-8b17-8cd8a978020e",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T05:51:14.381155Z",
     "start_time": "2025-01-19T05:51:14.377346Z"
    }
   },
   "source": [
    "llm_with_tools.kwargs[\"tools\"]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'get_weather',\n",
       "   'description': \"查询即时天气函数\\n:param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入'Beijing'；\\n:return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息\",\n",
       "   'parameters': {'properties': {'loc': {}},\n",
       "    'required': ['loc'],\n",
       "    'type': 'object'}}}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "f580c2be-b5a4-48d1-ac7b-23b0a0057a0f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;从输出上看，返回的数据中存在一个`additional_kwargs` 属性，这个属性在LangChain中是用来传递有关Messages的附加信息，主要用于特定于提供者而非通用的输入参数，在这里可能明显看到就是OpenAI 的 function_call 信息 。而上述两行代码，其本质上实现的就是我们在上面手动实现的第一轮对话过程：即接受输入的Prompt，提取关键词并正确识别需要调用的外部函数的这个过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26c198-b06c-4028-a000-07c245d0352b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在识别出基于输入Prompt的具体外部函数执行需求后，下一步是执行该函数并获取其数据输出。实现这一过程，将再次用到输出解析器（Output Parsers）。我们在上一课中已经介绍了输出解析器，它是一个用于解析大模型的输出并将其转换成更适用的格式的模块。\n",
    "\n",
    "&emsp;&emsp;那么对于Function Calling的结果应该如何解析，在上面手动实现的过程我们已经给大家介绍过了，LangChain对这一过程进行了抽象，与我们手动实现的基本逻辑保持一致。这一部分在LangChain的架构中被归类为Output Parser模块。由于已进行封装，这意味着我们可以在LangChain框架内直接调用此功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed1bea8-04bf-4c6a-be41-dbca497ed5a8",
   "metadata": {},
   "source": [
    "### 如何设置输出解析器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60781fce-c2f9-437a-b0c9-e0b092f40445",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`JsonOutputKeyToolsParser`继承了` JsonOutputToolsParser `类构建工具调用模型，它会将 OpenAI 函数调用响应转换为 {\"type\": \"TOOL_NAME\", \"args\": {...}} 字典列表调用和调用它们的参数。"
   ]
  },
  {
   "cell_type": "code",
   "id": "e2ad7bb7-3046-411c-ab09-e4d37405bb04",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T05:56:04.664395Z",
     "start_time": "2025-01-19T05:56:04.617795Z"
    }
   },
   "source": [
    "from langchain.output_parsers import JsonOutputKeyToolsParser"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "e097f8c0-033c-4c6e-b65a-f678b43f5b87",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T05:58:28.847081Z",
     "start_time": "2025-01-19T05:58:27.411803Z"
    }
   },
   "source": [
    "chain = llm_with_tools | JsonOutputKeyToolsParser(key_name='get_weather', first_tool_only=True)\n",
    "chain.invoke(\"杭州的天气怎么样？\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc': 'Hangzhou'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "2b52a970-1c2d-4a5e-87ee-196b26ddf294",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T05:58:37.665691Z",
     "start_time": "2025-01-19T05:58:36.280032Z"
    }
   },
   "source": [
    "chain = llm_with_tools | JsonOutputKeyToolsParser(key_name='get_weather', first_tool_only=True)\n",
    "chain.invoke(\"今天北京的天气好吗？\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc': 'Beijing'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "4387a2f4-117f-41e4-82ce-301d28dda1b9",
   "metadata": {},
   "source": "&emsp;&emsp;通过仅两行代码，就已经实现了根据输入（Prompt）正确匹配传入参数的功能。如果想实际调用该工具，只需将其传递给工具即可："
  },
  {
   "cell_type": "code",
   "id": "4753430c-600a-4178-8c65-354c1f9e4b3a",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T06:00:37.343210Z",
     "start_time": "2025-01-19T06:00:34.956211Z"
    }
   },
   "source": [
    "chain = llm_with_tools | JsonOutputKeyToolsParser(key_name='get_weather', first_tool_only=True) | get_weather\n",
    "chain.invoke(\"北京现在的天气怎么样？\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"coord\": {\"lon\": 116.3972, \"lat\": 39.9075}, \"weather\": [{\"id\": 800, \"main\": \"Clear\", \"description\": \"\\\\u6674\", \"icon\": \"01d\"}], \"base\": \"stations\", \"main\": {\"temp\": 9.94, \"feels_like\": 8.32, \"temp_min\": 9.94, \"temp_max\": 9.94, \"pressure\": 1020, \"humidity\": 18, \"sea_level\": 1020, \"grnd_level\": 1015}, \"visibility\": 10000, \"wind\": {\"speed\": 3.21, \"deg\": 360, \"gust\": 4.79}, \"clouds\": {\"all\": 1}, \"dt\": 1737265877, \"sys\": {\"type\": 1, \"id\": 9609, \"country\": \"CN\", \"sunrise\": 1737243141, \"sunset\": 1737278242}, \"timezone\": 28800, \"id\": 1816670, \"name\": \"Beijing\", \"cod\": 200}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "fedfffcd-708d-48a7-a819-bf4c63885f7b",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T06:00:43.812619Z",
     "start_time": "2025-01-19T06:00:41.106496Z"
    }
   },
   "source": [
    "chain = llm_with_tools | JsonOutputKeyToolsParser(key_name='get_weather', first_tool_only=True) | get_weather\n",
    "chain.invoke(\"今天杭州的天气好吗？\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"coord\": {\"lon\": 120.1614, \"lat\": 30.2937}, \"weather\": [{\"id\": 800, \"main\": \"Clear\", \"description\": \"\\\\u6674\", \"icon\": \"01d\"}], \"base\": \"stations\", \"main\": {\"temp\": 16.36, \"feels_like\": 14.55, \"temp_min\": 16.36, \"temp_max\": 16.36, \"pressure\": 1017, \"humidity\": 19, \"sea_level\": 1017, \"grnd_level\": 1015}, \"visibility\": 10000, \"wind\": {\"speed\": 0.99, \"deg\": 340, \"gust\": 2.14}, \"clouds\": {\"all\": 0}, \"dt\": 1737266384, \"sys\": {\"country\": \"CN\", \"sunrise\": 1737240942, \"sunset\": 1737278634}, \"timezone\": 28800, \"id\": 1808926, \"name\": \"Hangzhou\", \"cod\": 200}'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "048303e5-505a-438b-90d8-90d3a077fdc5",
   "metadata": {},
   "source": [
    "&emsp;&emsp;通过这个流程，我们可以根据输入实时查询OpenWeather的API，并获取最终的查询结果。如果想进一步得到最终的回复，实现的逻辑应当是将返回的信息添加到Messages中，利用这些提示数据引导模型生成最终的回复。具体转化为代码的逻辑如下："
   ]
  },
  {
   "cell_type": "code",
   "id": "34991a13-0105-4135-b99f-6c6685dea014",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T06:01:44.899586Z",
     "start_time": "2025-01-19T06:01:44.896443Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"天气信息来源于OpenWeather API：https://api.openweathermap.org/data/2.5/weather\"),\n",
    "        (\"system\", \"这是实时的天气数据：{weather_data}\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "5d3db918-202a-49cd-9570-13055ac268dd",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T06:02:02.544296Z",
     "start_time": "2025-01-19T06:01:58.551496Z"
    }
   },
   "source": [
    "chain = llm_with_tools | JsonOutputKeyToolsParser(key_name='get_weather', first_tool_only=True) | get_weather\n",
    "weather_data = chain.invoke(\"今天杭州的天气好吗？\")"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "6cd09ac6-f52b-4c3e-ae5f-8420f95ed6e6",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T06:02:07.887391Z",
     "start_time": "2025-01-19T06:02:07.882756Z"
    }
   },
   "source": [
    "weather_data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"coord\": {\"lon\": 120.1614, \"lat\": 30.2937}, \"weather\": [{\"id\": 800, \"main\": \"Clear\", \"description\": \"\\\\u6674\", \"icon\": \"01d\"}], \"base\": \"stations\", \"main\": {\"temp\": 16.36, \"feels_like\": 14.55, \"temp_min\": 16.36, \"temp_max\": 16.36, \"pressure\": 1017, \"humidity\": 19, \"sea_level\": 1017, \"grnd_level\": 1015}, \"visibility\": 10000, \"wind\": {\"speed\": 0.99, \"deg\": 340, \"gust\": 2.14}, \"clouds\": {\"all\": 0}, \"dt\": 1737266384, \"sys\": {\"country\": \"CN\", \"sunrise\": 1737240942, \"sunset\": 1737278634}, \"timezone\": 28800, \"id\": 1808926, \"name\": \"Hangzhou\", \"cod\": 200}'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "d1843ee3-b727-4490-94f6-1a915c6350c9",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T06:02:20.351988Z",
     "start_time": "2025-01-19T06:02:20.347423Z"
    }
   },
   "source": [
    "messages = chat_template.format_messages(weather_data=weather_data, user_input=\"今天杭州的天气好吗？\")\n",
    "messages"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='天气信息来源于OpenWeather API：https://api.openweathermap.org/data/2.5/weather', additional_kwargs={}, response_metadata={}),\n",
       " SystemMessage(content='这是实时的天气数据：{\"coord\": {\"lon\": 120.1614, \"lat\": 30.2937}, \"weather\": [{\"id\": 800, \"main\": \"Clear\", \"description\": \"\\\\u6674\", \"icon\": \"01d\"}], \"base\": \"stations\", \"main\": {\"temp\": 16.36, \"feels_like\": 14.55, \"temp_min\": 16.36, \"temp_max\": 16.36, \"pressure\": 1017, \"humidity\": 19, \"sea_level\": 1017, \"grnd_level\": 1015}, \"visibility\": 10000, \"wind\": {\"speed\": 0.99, \"deg\": 340, \"gust\": 2.14}, \"clouds\": {\"all\": 0}, \"dt\": 1737266384, \"sys\": {\"country\": \"CN\", \"sunrise\": 1737240942, \"sunset\": 1737278634}, \"timezone\": 28800, \"id\": 1808926, \"name\": \"Hangzhou\", \"cod\": 200}', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='今天杭州的天气好吗？', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "2721595c-03dd-4020-adfa-49f1e26268ee",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T06:02:31.059441Z",
     "start_time": "2025-01-19T06:02:28.915387Z"
    }
   },
   "source": [
    "response = chat.invoke(messages)\n",
    "response"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='根据提供的天气数据，今天杭州的天气非常好。天气状况为“晴”（Clear），温度为16.36°C，体感温度为14.55°C。湿度为19%，风速为0.99米/秒，能见度为10000米。总体来说，今天杭州的天气非常适合外出活动。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 277, 'total_tokens': 342, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 277}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3a5770e1b4', 'finish_reason': 'stop', 'logprobs': None}, id='run-0ed79502-942c-4944-8a34-964fe674c240-0', usage_metadata={'input_tokens': 277, 'output_tokens': 65, 'total_tokens': 342, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "1adf6b70-ce07-441f-9ccd-946eb91e507d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T06:02:36.266649Z",
     "start_time": "2025-01-19T06:02:36.263002Z"
    }
   },
   "source": [
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据提供的天气数据，今天杭州的天气非常好。天气状况为“晴”（Clear），温度为16.36°C，体感温度为14.55°C。湿度为19%，风速为0.99米/秒，能见度为10000米。总体来说，今天杭州的天气非常适合外出活动。\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "0ccb1543-c1d9-4f32-8e77-071037999a83",
   "metadata": {},
   "source": [
    "&emsp;&emsp;至此，仅通过几行简单的代码，我们就已经快速实现了OpenAI的Function Calling功能，这得益于LangChain中预先抽象好的模块。接下来我们可以整理一下有效代码，如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de7baab-ede3-4550-abf8-145c54c585e4",
   "metadata": {},
   "source": [
    "#### 步骤1 构建外部函数"
   ]
  },
  {
   "cell_type": "code",
   "id": "21610811-1d89-4ef9-817f-37787b95e44e",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T06:35:43.538764Z",
     "start_time": "2025-01-19T06:35:43.533148Z"
    }
   },
   "source": [
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(loc):\n",
    "    \"\"\"\n",
    "    查询即时天气函数\n",
    "    :param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，\\\n",
    "    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入'Beijing'；\n",
    "    :return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather\\\n",
    "    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息\n",
    "    \"\"\"\n",
    "    # Step 1.构建请求\n",
    "    url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "\n",
    "    # Step 2.设置查询参数\n",
    "    params = {\n",
    "        \"q\": loc,\n",
    "        \"appid\": 'ca673e17d804b89c0d70b56855cb88a9',  # 输入API key\n",
    "        \"units\": \"metric\",  # 使用摄氏度而不是华氏度\n",
    "        \"lang\": \"zh_cn\"  # 输出语言为简体中文\n",
    "    }\n",
    "\n",
    "    # Step 3.发送GET请求\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    # Step 4.解析响应\n",
    "    data = response.json()\n",
    "    return json.dumps(data)"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "1857b4b7-e6da-482c-9557-295be874ec1c",
   "metadata": {},
   "source": [
    "#### 步骤2 通过LangChain构建Funcation Calling Chain"
   ]
  },
  {
   "cell_type": "code",
   "id": "1b9fc98e-1c21-4b61-a3bc-0316f51aaf64",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T06:11:20.958467Z",
     "start_time": "2025-01-19T06:11:14.314624Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 实例化大模型\n",
    "openai_chat = ChatOpenAI(model_name=\"deepseek-chat\", api_key=api_key, base_url=api_base)\n",
    "\n",
    "# 绑定外部工具\n",
    "llm_with_tools = openai_chat.bind_tools([get_weather])\n",
    "\n",
    "# 根据输入，调用指定的工具，并得到数据\n",
    "chain = llm_with_tools | JsonOutputKeyToolsParser(key_name='get_weather', first_tool_only=True) | get_weather\n",
    "weather_data = chain.invoke(\"今天杭州的天气好吗？\")\n",
    "\n",
    "# 构造输入模版，将工具返回的数据和当前的输入拼接到一起作为外部知识影响最终的输出\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"天气信息来源于OpenWeather API：https://api.openweathermap.org/data/2.5/weather\"),\n",
    "        (\"system\", \"这是实时的天气数据：{weather_data}\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 生成messages\n",
    "messages = chat_template.format_messages(weather_data=weather_data, user_input=\"今天杭州的天气好吗？\")\n",
    "\n",
    "# 实际进行推理\n",
    "response = openai_chat.invoke(messages)\n",
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据提供的天气数据，今天杭州的天气非常好。天气状况为“晴”（Clear），温度为16.36°C，体感温度为14.55°C。湿度为19%，风速为0.99米/秒，能见度为10000米。总体来说，今天杭州的天气非常适合外出活动。\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "7eddfc3a-4085-49bc-b0fe-0fe0a801df2c",
   "metadata": {},
   "source": [
    "#### 如何自定义输出解析器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79c0805-e035-43f3-bdb6-dadb8732a82d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;所谓自定义输出解析器想要达到的效果是：通过该解析器，将大模型输出构造为自定义格式。我们在上一步使用的LangChain预置的`JsonOutputKeyToolsParser`，该解析器返回的是OpenWeather API返回的Json数据，其形式如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "06abb7cb-0d70-4fde-b859-8e97cc303679",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"coord\": {\"lon\": 116.3972, \"lat\": 39.9075}, \"weather\": [{\"id\": 804, \"main\": \"Clouds\", \"description\": \"\\u9634\\uff0c\\u591a\\u4e91\", \"icon\": \"04d\"}], \"base\": \"stations\", \"main\": {\"temp\": 26.94, \"feels_like\": 26.27, \"temp_min\": 26.94, \"temp_max\": 26.94, \"pressure\": 1001, \"humidity\": 27, \"sea_level\": 1001, \"grnd_level\": 995}, \"visibility\": 10000, \"wind\": {\"speed\": 3.85, \"deg\": 222, \"gust\": 6.13}, \"clouds\": {\"all\": 94}, \"dt\": 1715318552, \"sys\": {\"type\": 1, \"id\": 9609, \"country\": \"CN\", \"sunrise\": 1715288663, \"sunset\": 1715339838}, \"timezone\": 28800, \"id\": 1816670, \"name\": \"Beijing\", \"cod\": 200}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 实例化大模型\n",
    "openai_chat = ChatOpenAI(model_name=\"deepseek-chat\", api_key=api_key, base_url=api_base)\n",
    "\n",
    "# 绑定外部工具\n",
    "llm_with_tools = openai_chat.bind_tools([get_weather])\n",
    "\n",
    "# 根据输入，调用指定的工具，并得到数据\n",
    "chain = llm_with_tools | JsonOutputKeyToolsParser(key_name='get_weather', first_tool_only=True) | get_weather\n",
    "weather_data = chain.invoke(\"今天北京的天气好吗？\")\n",
    "print(weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "id": "57bec2f7-fca0-475a-9886-5910bc9d7b7f",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T06:25:47.999720Z",
     "start_time": "2025-01-19T06:25:41.471005Z"
    }
   },
   "source": [
    "weather_data = chain.invoke(\"上海现在什么天气？\")\n",
    "print(weather_data)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前上海的天气情况如下：\n",
      "\n",
      "- **天气状况**：晴\n",
      "- **温度**：15.65°C\n",
      "- **体感温度**：13.58°C\n",
      "- **最低温度**：15.65°C\n",
      "- **最高温度**：15.65°C\n",
      "- **气压**：1017 hPa\n",
      "- **湿度**：12%\n",
      "- **能见度**：10000米\n",
      "- **风速**：3.26米/秒，风向为291度（西北偏西）\n",
      "- **阵风风速**：5.36米/秒\n",
      "- **云量**：0%（无云）\n",
      "- **日出时间**：1737240743（时间戳，需转换为具体时间）\n",
      "- **日落时间**：1737278210（时间戳，需转换为具体时间）\n",
      "- **时区**：UTC+8\n",
      "\n",
      "总体来说，上海目前天气晴朗，温度适中，风力较小，适合户外活动。\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c7a06e-782a-4579-ace9-628083d5cbe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "id": "51e676cc-6c11-4f20-90ef-e0df5c9e22d1",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T10:57:47.303046Z",
     "start_time": "2025-01-19T10:57:47.201202Z"
    }
   },
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "def final_response(ai_message: str) -> str:\n",
    "    data = json.loads(ai_message)\n",
    "\n",
    "    chat_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\",\n",
    "             \"这是实时的{city}的天气数据，信息来源于OpenWeather API：https://api.openweathermap.org/data/2.5/weather, 详细的数据是：{detail}\",),\n",
    "            (\"system\", \"请你解析该数据，以自然语言的形式回复\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 生成messages\n",
    "    messages = chat_template.format_messages(city=data[\"name\"], detail=data)\n",
    "\n",
    "    openai_chat = ChatOpenAI(model_name=\"deepseek-chat\", api_key=api_key, base_url=api_base)\n",
    "    response = openai_chat.invoke(messages)\n",
    "    return response.content"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "id": "f75b985e-defc-4fcf-9f9e-f3fff5c933a9",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T06:45:24.734993Z",
     "start_time": "2025-01-19T06:45:17.308905Z"
    }
   },
   "source": [
    "chain = llm_with_tools | JsonOutputKeyToolsParser(key_name='get_weather',\n",
    "                                                  first_tool_only=True) | get_weather | final_response\n",
    "final_response = chain.invoke(\"北京现在的天气怎么样？\")\n",
    "final_response.replace('\\n', '')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'根据OpenWeather API提供的数据，以下是北京市当前的天气情况：- **天气状况**：晴- **温度**：8.94°C- **体感温度**：7.28°C- **最低温度**：8.94°C- **最高温度**：8.94°C- **气压**：1019 hPa- **湿度**：17%- **能见度**：10000米- **风速**：2.93米/秒- **风向**：4度- **阵风速度**：4.28米/秒- **云量**：0%（无云）- **日出时间**：1737243141（时间戳，需转换为当地时间）- **日落时间**：1737278242（时间戳，需转换为当地时间）总体来说，北京市当前天气晴朗，温度适中，风力较小，湿度较低，能见度良好。'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "chain = llm_with_tools | JsonOutputKeyToolsParser(key_name='get_weather',\n",
    "                                                  first_tool_only=True) | get_weather | final_response\n",
    "final_response = chain.invoke(\"上海现在是什么天气状况？\")\n",
    "final_response.replace('\\n', '')"
   ],
   "id": "e96cca7c1eda9b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8 LangChain调用开源模型的Funcation calling",
   "id": "6d742c19b13e969b"
  },
  {
   "cell_type": "markdown",
   "id": "e9e103af-dd57-48a7-9d1b-f0e8bd775020",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先我们需要明确的是，OpenAI的GPT系列模型在很大程度上影响了大模型技术发展的开发范式和标准。所以无论是Qwen、ChatGLM等模型，它们的使用方法和函数调用逻辑基本遵循OpenAI定义的规范，没有太大差异。也正是这种一致性，现在大部分的开源项目才能够通过一个较为通用的接口来接入和使用不同的模型。这种兼容性和模型间的相似性之间存在直接联系。LangChain也不例外。\n",
    "\n",
    "> Ollama Functions：https://python.langchain.com/docs/integrations/chat/ollama_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b21882-e327-4e43-b548-d455e8e20c8d",
   "metadata": {},
   "source": [
    "```python\n",
    "    model = model.bind(\n",
    "    functions=[\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, \" \"e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "id": "21929dc6-2690-4d5a-a359-07112e031c1a",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T06:56:19.923978Z",
     "start_time": "2025-01-19T06:56:06.465505Z"
    }
   },
   "source": [
    "# ! pip install langchain_experimental\n",
    "! pip install -U langchain-ollama"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-ollama\n",
      "  Downloading langchain_ollama-0.2.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-ollama) (0.3.28)\n",
      "Collecting ollama<1,>=0.4.4 (from langchain-ollama)\n",
      "  Downloading ollama-0.4.6-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (0.2.6)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (2.10.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (4.12.2)\n",
      "Collecting httpx<0.28.0,>=0.27.0 (from ollama<1,>=0.4.4->langchain-ollama)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: anyio in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (4.7.0)\n",
      "Requirement already satisfied: certifi in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (3.10.13)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\py_pjt\\chatglm3-main\\chatglm3-main\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (2.3.0)\n",
      "Downloading langchain_ollama-0.2.2-py3-none-any.whl (18 kB)\n",
      "Downloading ollama-0.4.6-py3-none-any.whl (13 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: httpx, ollama, langchain-ollama\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.28.1\n",
      "    Uninstalling httpx-0.28.1:\n",
      "      Successfully uninstalled httpx-0.28.1\n",
      "Successfully installed httpx-0.27.2 langchain-ollama-0.2.2 ollama-0.4.6\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "id": "05065f99-66e5-494d-a301-8ade63d6b18c",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T10:21:42.419412Z",
     "start_time": "2025-01-19T10:21:42.179394Z"
    }
   },
   "source": [
    "# from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_ollama import ChatOllama\n",
    "from openai import OpenAI\n",
    "from langchain_core.messages import HumanMessage"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "ab24c573-e84e-43f9-b5d4-cef66dbb40ee",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T10:21:47.037532Z",
     "start_time": "2025-01-19T10:21:45.096471Z"
    }
   },
   "source": [
    "# ollama_key=\"sk-7800dc8fded44016b70814bf80f4c78f\"\n",
    "# ollama_key=\"\"\n",
    "# api_base=\"http://localhost:11434\"\n",
    "# client = OpenAI(api_key=ollama_key, base_url=api_base)\n",
    "model = ChatOllama(\n",
    "    # model=\"qwen:7b-chat\"\n",
    "    model=\"qwen2.5:1.5b\",\n",
    "    basee_url=\"http://localhost:11434/\"\n",
    ")\n",
    "# model.invoke(\"你好！\")\n",
    "messages = [HumanMessage(content=\"你好，吃了吗?\")]\n",
    "\n",
    "result = model.invoke(messages)\n",
    "result"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！我没有吃过食物。我是人工智能助手Qwen，由阿里巴巴集团研发的模型，我不能体验实际生活或用餐。如果你有任何问题或需要帮助，请告诉我！', additional_kwargs={}, response_metadata={'model': 'qwen2.5:1.5b', 'created_at': '2025-01-19T10:21:47.0333945Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1669494600, 'load_duration': 1092724100, 'prompt_eval_count': 34, 'prompt_eval_duration': 112000000, 'eval_count': 37, 'eval_duration': 213000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-401f8252-c160-4c05-8c48-54e410ed49a9-0', usage_metadata={'input_tokens': 34, 'output_tokens': 37, 'total_tokens': 71})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "ce2e999a-8963-4373-b3db-61d6d128308b",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T10:54:09.026302Z",
     "start_time": "2025-01-19T10:54:09.019409Z"
    }
   },
   "source": [
    "@tool\n",
    "def get_weather(loc):\n",
    "    \"\"\"\n",
    "    查询即时天气函数\n",
    "    :param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，\\\n",
    "    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入'Beijing'；\n",
    "    :return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather\\\n",
    "    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息\n",
    "    \"\"\"\n",
    "    # Step 1.构建请求\n",
    "    url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "    open_weather_key = \"ca673e17d804b89c0d70b56855cb88a9\"\n",
    "    # Step 2.设置查询参数\n",
    "    params = {\n",
    "        \"q\": loc,\n",
    "        \"appid\": open_weather_key,  # 输入API key\n",
    "        \"units\": \"metric\",  # 使用摄氏度而不是华氏度\n",
    "        \"lang\": \"zh_cn\"  # 输出语言为简体中文\n",
    "    }\n",
    "\n",
    "    # Step 3.发送GET请求\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    # Step 4.解析响应\n",
    "    data = response.json()\n",
    "    return json.dumps(data)"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "64d92475-1299-422c-8bd8-b4aa5ff0736c",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T09:54:54.275069Z",
     "start_time": "2025-01-19T09:54:54.271562Z"
    }
   },
   "source": "from langchain_core.utils.function_calling import convert_to_openai_function, convert_to_openai_tool",
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "id": "b4c975dd-c57c-46d5-866c-f28e58d102cc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`convert_to_openai_function`的功能是将外部函数转化成Json Schema的表示，使用方法如下："
   ]
  },
  {
   "cell_type": "code",
   "id": "bf46abed-86ed-4518-ad04-d4f09e1497f3",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T10:21:59.539932Z",
     "start_time": "2025-01-19T10:21:59.535220Z"
    }
   },
   "source": [
    "get_weather_json_schema = json.dumps(convert_to_openai_function(get_weather), ensure_ascii=False)\n",
    "print(get_weather_json_schema)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"get_weather\", \"description\": \"查询即时天气函数\\n:param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入'Beijing'；\\n:return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息\", \"parameters\": {\"properties\": {\"loc\": {}}, \"required\": [\"loc\"], \"type\": \"object\"}}\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "a6bc1fd0-4b95-44a7-ae8d-ff9d77e65fae",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T10:22:04.071935Z",
     "start_time": "2025-01-19T10:22:04.068761Z"
    }
   },
   "source": [
    "print(type(get_weather_json_schema))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "bde3d501-760f-44a7-b969-5942d21199e0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;上述通过`json.dumps`是为了更好的显示输出，而实际上需要传入的Json Schema需要是字典形式，直接使用`convert_to_openai_function`方法进行转化。"
   ]
  },
  {
   "cell_type": "code",
   "id": "b88c4d1a-8c44-4e07-81a6-c283a0af4720",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T10:27:25.418938Z",
     "start_time": "2025-01-19T10:27:25.414485Z"
    }
   },
   "source": [
    "# get_weather_json_schema = convert_to_openai_function(get_weather)\n",
    "get_weather_json_schema = convert_to_openai_tool(get_weather)\n",
    "print(get_weather_json_schema)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'function', 'function': {'name': 'get_weather', 'description': \"查询即时天气函数\\n:param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入'Beijing'；\\n:return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息\", 'parameters': {'properties': {'loc': {}}, 'required': ['loc'], 'type': 'object'}}}\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "383e6030-6902-43f9-a8b3-aaaa48b3a72b",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T10:27:28.709125Z",
     "start_time": "2025-01-19T10:27:28.705480Z"
    }
   },
   "source": [
    "print(type(get_weather_json_schema))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "fd418f82-f815-4e57-85e9-d96b4e6da2a4",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T10:27:31.722032Z",
     "start_time": "2025-01-19T10:27:31.718195Z"
    }
   },
   "source": [
    "functions_list = [get_weather_json_schema]\n",
    "functions_list"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'get_weather',\n",
       "   'description': \"查询即时天气函数\\n:param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入'Beijing'；\\n:return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息\",\n",
       "   'parameters': {'properties': {'loc': {}},\n",
       "    'required': ['loc'],\n",
       "    'type': 'object'}}}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "9d97db5e-1bd7-4aae-a097-59d6a8f12cdf",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T10:49:25.148102Z",
     "start_time": "2025-01-19T10:49:25.140176Z"
    }
   },
   "source": [
    "# model = model.bind_tools(\n",
    "#     tools=functions_list,\n",
    "#     tool_choice={\"name\": \"get_weather\"},\n",
    "# )\n",
    "model = model.bind_tools([get_weather])\n",
    "model"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOllama(model='qwen2.5:1.5b'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'get_weather', 'description': \"查询即时天气函数\\n:param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入'Beijing'；\\n:return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息\", 'parameters': {'properties': {'loc': {}}, 'required': ['loc'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "43e05d40-c8d1-4aac-9879-a154e9f6440f",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T10:49:50.330565Z",
     "start_time": "2025-01-19T10:49:48.574221Z"
    }
   },
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "input_message = HumanMessage(content=\"查询一下北京的天气\")\n",
    "final_response = model.invoke([input_message])\n",
    "# final_response = final_response[0].message.content.replace('\\n', '')\n",
    "print(final_response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={} response_metadata={'model': 'qwen2.5:1.5b', 'created_at': '2025-01-19T10:49:50.3278469Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1750747200, 'load_duration': 1103776500, 'prompt_eval_count': 257, 'prompt_eval_duration': 178000000, 'eval_count': 21, 'eval_duration': 134000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-abe9fa68-5d4c-4b2a-b5ac-7045c1a70a9d-0' tool_calls=[{'name': 'get_weather', 'args': {'loc': 'Beijing'}, 'id': 'b26b5045-2ed4-4a50-bd2e-ef7efe094e4f', 'type': 'tool_call'}] usage_metadata={'input_tokens': 257, 'output_tokens': 21, 'total_tokens': 278}\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39703102-f784-4a0d-80dd-65db27a02cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c2984be-2f05-45ae-a035-6d86a08510bf",
   "metadata": {},
   "source": [
    "&emsp;&emsp;将`get_weather`的Json Schma表示放在一个列表中。使用model.bind进行传入。"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "edca3b2fb49aa7b3"
  },
  {
   "cell_type": "code",
   "id": "785bc670-7618-40a8-9e67-f102f239344a",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T09:11:59.149901Z",
     "start_time": "2025-01-19T09:11:59.100978Z"
    }
   },
   "source": [
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "2989e34d-3525-4024-9e3f-cfd5387bdd26",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T11:05:58.041625Z",
     "start_time": "2025-01-19T11:05:55.593952Z"
    }
   },
   "source": [
    "# 根据输入，调用指定的工具，并得到数据\n",
    "# chain = model | JsonKeyOutputFunctionsParser(key_name='loc', first_tool_only=True) | get_weather\n",
    "chain = model | JsonOutputKeyToolsParser(key_name='get_weather', first_tool_only=True) | get_weather | final_resonse\n",
    "weather_data = chain.invoke(\"上海现在什么天气？\")  \n",
    "print(weather_data)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coord': {'lon': 121.4581, 'lat': 31.2222}, 'weather': [{'id': 800, 'main': 'Clear', 'description': '晴', 'icon': '01n'}], 'base': 'stations', 'main': {'temp': 11.86, 'feels_like': 9.6, 'temp_min': 11.86, 'temp_max': 11.86, 'pressure': 1018, 'humidity': 19, 'sea_level': 1018, 'grnd_level': 1017}, 'visibility': 10000, 'wind': {'speed': 0.36, 'deg': 106, 'gust': 0.48}, 'clouds': {'all': 0}, 'dt': 1737284258, 'sys': {'country': 'CN', 'sunrise': 1737240743, 'sunset': 1737278210}, 'timezone': 28800, 'id': 1796236, 'name': 'Shanghai', 'cod': 200}\n",
      "当前的温度是11.86摄氏度，感觉温度是9.6摄氏度。大气压力是1018百帕斯卡，湿度是19%。上海的大气可见度为1公里。风速为0.36米/秒，最大风速为0.48米/秒。目前没有云量，整体天气状况晴朗。当前时间的服务器时间是北京时间27日的17:37,08:37。上海的时区是加西八小时，对应于美国西部的时间是星期五的6点57分。这个城市的ID为1796236。\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "id": "09737b28-a709-4462-bfce-ec7d1f40ac51",
   "metadata": {},
   "source": [
    "到目前为止获取天气的数据了！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae163de6-4e9d-419b-b2c4-4a2d0d455819",
   "metadata": {},
   "source": [
    "#### 完整流程演示"
   ]
  },
  {
   "cell_type": "code",
   "id": "4e4fc05ee3414c07",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T10:20:04.916470Z",
     "start_time": "2025-01-19T10:20:04.909390Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "import json\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function, convert_to_openai_tool\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from langchain.output_parsers import JsonOutputKeyToolsParser\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(loc):\n",
    "    \"\"\"\n",
    "    查询即时天气函数\n",
    "    :param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，\\\n",
    "    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入'Beijing'；\n",
    "    :return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather\\\n",
    "    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息\n",
    "    \"\"\"\n",
    "    # Step 1.构建请求\n",
    "    url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "    open_weather_key = \"ca673e17d804b89c0d70b56855cb88a9\"\n",
    "\n",
    "    # Step 2.设置查询参数\n",
    "    params = {\n",
    "        \"q\": loc,\n",
    "        \"appid\": open_weather_key,  # 输入API key\n",
    "        \"units\": \"metric\",  # 使用摄氏度而不是华氏度\n",
    "        \"lang\": \"zh_cn\"  # 输出语言为简体中文\n",
    "    }\n",
    "\n",
    "    # Step 3.发送GET请求\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    # Step 4.解析响应\n",
    "    data = response.json()\n",
    "    return json.dumps(data)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T11:04:52.881599Z",
     "start_time": "2025-01-19T11:04:52.877432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def final_resonse(ai_message: str) -> str:\n",
    "    data = json.loads(ai_message)\n",
    "    print(data)\n",
    "\n",
    "    chat_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\",\n",
    "             \"这是实时的{city}的天气数据，信息来源于OpenWeather API：https://api.openweathermap.org/data/2.5/weather, 详细的数据是：{detail}\",),\n",
    "            (\"system\", \"请你解析该数据，以自然语言的形式回复\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 生成messages\n",
    "    messages = chat_template.format_messages(city=data[\"name\"], detail=data)\n",
    "\n",
    "    # 实例化Ollama启动的模型\n",
    "    ollama_llm = ChatOllama(model=\"qwen2.5:1.5b\", basee_url=\"http://localhost:11434/\")\n",
    "    response = ollama_llm.invoke(messages)\n",
    "    return response.content"
   ],
   "id": "fb4df0bc-506e-461e-8a3a-1b3cd5f63f28",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "21676703d1217564"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T10:20:07.405012Z",
     "start_time": "2025-01-19T10:20:07.400491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get_weather_json_schema = convert_to_openai_function(get_weather)\n",
    "get_weather_json_schema = convert_to_openai_tool(get_weather)\n",
    "functions_list = [get_weather_json_schema]"
   ],
   "id": "ee1ff0ad0292e75a",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T10:20:08.446041Z",
     "start_time": "2025-01-19T10:20:08.198528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ChatOllama(\n",
    "    # model=\"qwen:7b-chat\"\n",
    "    model=\"qwen2.5:1.5b\",\n",
    "    basee_url=\"http://localhost:11434/\"\n",
    ")"
   ],
   "id": "9db86d749c2af737",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "93d7d7d3-50af-4b31-b76a-53de5db4e0e0",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-19T11:06:46.634107Z",
     "start_time": "2025-01-19T11:06:43.874562Z"
    }
   },
   "source": [
    "# model = model.bind_tools(\n",
    "#     tools=functions_list,\n",
    "#     tool_choice={\"name\": \"get_weather\"},\n",
    "# )\n",
    "model.bind_tools([get_weather])\n",
    "chain = model | JsonOutputKeyToolsParser(key_name='get_weather', first_tool_only=True) | get_weather | final_resonse\n",
    "# model.invoke(\"查询一下北京的天气\")\n",
    "final_resonse = chain.invoke(\"上海现在什么天气？\")\n",
    "print(final_resonse)\n",
    "final_resonse.replace('\\n', '')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coord': {'lon': 121.4581, 'lat': 31.2222}, 'weather': [{'id': 800, 'main': 'Clear', 'description': '晴', 'icon': '01n'}], 'base': 'stations', 'main': {'temp': 11.86, 'feels_like': 9.6, 'temp_min': 11.86, 'temp_max': 11.86, 'pressure': 1018, 'humidity': 19, 'sea_level': 1018, 'grnd_level': 1017}, 'visibility': 10000, 'wind': {'speed': 0.36, 'deg': 106, 'gust': 0.48}, 'clouds': {'all': 0}, 'dt': 1737284258, 'sys': {'country': 'CN', 'sunrise': 1737240743, 'sunset': 1737278210}, 'timezone': 28800, 'id': 1796236, 'name': 'Shanghai', 'cod': 200}\n",
      "当前上海市的天气情况是晴朗的。具体来说，温度为11.86摄氏度（大约等于31华氏度），湿度为19%，气压为1018百帕，风速为每小时0.36公里，风向为106度，最大风速为每小时0.48公里。空气质量良好，没有云层覆盖，大气透明度非常好。上海市位于东经121.4581，北纬31.2222。最新的天气数据是在1737284258，即北京时间的前一天下午6点。当前时间是1737284258（UTC+8）后。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'当前上海市的天气情况是晴朗的。具体来说，温度为11.86摄氏度（大约等于31华氏度），湿度为19%，气压为1018百帕，风速为每小时0.36公里，风向为106度，最大风速为每小时0.48公里。空气质量良好，没有云层覆盖，大气透明度非常好。上海市位于东经121.4581，北纬31.2222。最新的天气数据是在1737284258，即北京时间的前一天下午6点。当前时间是1737284258（UTC+8）后。'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "id": "c95dee7d-0b0c-4925-95ed-ce7c62b96528",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
